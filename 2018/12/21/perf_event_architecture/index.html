<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.6.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.6.0" color="#222">









<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.6.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="为什么有了ftrace又出来一个perf？因为ftrace只管抓trace数据并没有分析，perf在trace数据分析方面做出了很多成果。 在trace数据采集方面，perf复用了ftrace的所有插桩点，并且加入了采样法(硬件PMU)。PMU是一种非常重要的数据采集方法，因为它大部分是硬件的，所以可以做到一些软件做不到的事情，获取到一些底层硬件的信息。 perf的基本包装模型是这样的，对每一个e">
<meta name="keywords" content="perf">
<meta property="og:type" content="article">
<meta property="og:title" content="Linux Perf 1.1、perf_event内核框架">
<meta property="og:url" content="http://yoursite.com/2018/12/21/perf_event_architecture/index.html">
<meta property="og:site_name" content="pwl999&#39;s blog">
<meta property="og:description" content="为什么有了ftrace又出来一个perf？因为ftrace只管抓trace数据并没有分析，perf在trace数据分析方面做出了很多成果。 在trace数据采集方面，perf复用了ftrace的所有插桩点，并且加入了采样法(硬件PMU)。PMU是一种非常重要的数据采集方法，因为它大部分是硬件的，所以可以做到一些软件做不到的事情，获取到一些底层硬件的信息。 perf的基本包装模型是这样的，对每一个e">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/images/perf_k/perf_k_event_cpu_view.png">
<meta property="og:image" content="http://yoursite.com/images/perf_k/perf_k_event_task_view.png">
<meta property="og:image" content="http://yoursite.com/images/perf_k/perf_k_perf_task_sched.png">
<meta property="og:image" content="http://yoursite.com/images/perf_k/perf_k_perf_task_sched_time_on_onecpu.png">
<meta property="og:image" content="http://yoursite.com/2018/12/21/perf_event_architecture/(/images/perf_k/perf_k_perf_task_sched_time_on_multicpu.png">
<meta property="og:image" content="http://yoursite.com/images/perf_k/perf_k_event_task_inherit.png">
<meta property="og:image" content="http://yoursite.com/images/perf_k/perf_k_event_pmu_provide_data.png">
<meta property="og:image" content="http://yoursite.com/images/perf_k/perf_k_event_ringbuffer.png">
<meta property="og:updated_time" content="2018-12-21T03:01:12.756Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Linux Perf 1.1、perf_event内核框架">
<meta name="twitter:description" content="为什么有了ftrace又出来一个perf？因为ftrace只管抓trace数据并没有分析，perf在trace数据分析方面做出了很多成果。 在trace数据采集方面，perf复用了ftrace的所有插桩点，并且加入了采样法(硬件PMU)。PMU是一种非常重要的数据采集方法，因为它大部分是硬件的，所以可以做到一些软件做不到的事情，获取到一些底层硬件的信息。 perf的基本包装模型是这样的，对每一个e">
<meta name="twitter:image" content="http://yoursite.com/images/perf_k/perf_k_event_cpu_view.png">






  <link rel="canonical" href="http://yoursite.com/2018/12/21/perf_event_architecture/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Linux Perf 1.1、perf_event内核框架 | pwl999's blog</title>
  












  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">pwl999's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/21/perf_event_architecture/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="pwl999">
      <meta itemprop="description" content="RTFSC(Read The Fucking Source Code)">
      <meta itemprop="image" content="/images/touxiang/ycqs.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="pwl999's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Linux Perf 1.1、perf_event内核框架

              
            
          </h1>
        

        <div class="post-meta">

          

        <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-12-21 10:18:21 / 修改时间：11:01:12" itemprop="dateCreated datePublished" datetime="2018-12-21T10:18:21+08:00">2018-12-21</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Trace/" itemprop="url" rel="index"><span itemprop="name">Trace</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/12/21/perf_event_architecture/#comments" itemprop="discussionUrl">
                
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/12/21/perf_event_architecture/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>为什么有了ftrace又出来一个perf？因为ftrace只管抓trace数据并没有分析，perf在trace数据分析方面做出了很多成果。</p>
<p>在trace数据采集方面，perf复用了ftrace的所有插桩点，并且加入了采样法(硬件PMU)。PMU是一种非常重要的数据采集方法，因为它大部分是硬件的，所以可以做到一些软件做不到的事情，获取到一些底层硬件的信息。</p>
<p>perf的基本包装模型是这样的，对每一个event分配一个对应的perf_event结构。所有对event的操作都是围绕perf_event来展开的：</p>
<ul>
<li>通过perf_event_open系统调用分配到perf_event以后，会返回一个文件句柄fd，这样这个perf_event结构可以通过read/write/ioctl/mmap通用文件接口来操作。</li>
<li>perf_event提供两种类型的trace数据：<strong>count</strong>和<strong>sample</strong>。count只是记录了event的发生次数，sample记录了大量信息(比如：IP、ADDR、TID、TIME、CPU、BT)。如果需要使用sample功能，需要给perf_event分配ringbuffer空间，并且把这部分空间通过mmap映射到用户空间。这和定位问题时从粗到细的思路是相符的，首先从counter的比例上找出问题热点在哪个模块，再使用详细记录抓取更多信息来进一步定位。具体分别对应“perf stat”和“perf record/report”命令。</li>
<li>perf的开销应该是比ftrace要大的，因为它给每个event都独立一套数据结构perf_event，对应独立的attr和pmu。在数据记录时的开销肯定大于ftrace，但是每个event的ringbuffer是独立的所以也不需要ftrace复杂的ringbuffer操作。perf也有比ftrace开销小的地方，它的sample数据存储的ringbuffer空间会通过mmap映射到到用户态，这样在读取数据的时候就会少一次拷贝。不过perf的设计初衷也不是让成百上千的event同时使用，只会挑出一些event重点debug。</li>
</ul>
<h1 id="0、perf-event的组织"><a href="#0、perf-event的组织" class="headerlink" title="0、perf_event的组织"></a>0、perf_event的组织</h1><p>从上面的描述看per就是一个个perf_event并不复杂，那么复杂在哪里呢？<strong>真正的难点</strong>在于对event的组织，怎么把全局的event的资源，按照用户的需要分割成cpu维度/task维度。</p>
<p>我们在分析问题的时候，并不是一下子深入到底层event直接来看数据(如果不加区别event记录的是整系统的数据)，我们会遵从系统-&gt;cpu-&gt;进程来分析问题。针对实际的需求，perf使用cpu维度/task维度来组织perf_event。</p>
<p>我们具体来看看perf_event的组织方法：</p>
<ul>
<li><p>1、<strong>cpu维度</strong>：</p>
<p>  使用perf_event_context类型的链表来连接本cpu的相关perf_event。这样的链表共有两条(perf_hw_context = 0, perf_sw_context = 1)，链表指针存放在per_cpu变量pmu-&gt;pmu_cpu_context.ctx中由所有同类型的pmu共享。</p>
<p>  <img src="/images/perf_k/perf_k_event_cpu_view.png" alt="perf_k_event_cpu_view"></p>
</li>
<li><p>2、<strong>task维度</strong>：</p>
<p>  使用perf_event_context类型的链表来连接本task的相关perf_event。这样的链表共有两条(perf_hw_context = 0, perf_sw_context = 1)，链表指针存放在task-&gt;perf_event_ctxp[ctxn]变量中。</p>
<p>  <img src="/images/perf_k/perf_k_event_task_view.png" alt="perf_k_event_task_view"></p>
</li>
<li><p>3、perf_event_open()系统调用使用cpu、pid两个参数来指定perf_event的cpu、task维度。  </p>
<p>  pid == 0: event绑定到当前进程；<br>  pid &gt; 0: event绑定到指定进程；<br>  pid == -1: event绑定到当前cpu的所有进程。<br>  cpu &gt;= 0: event绑定到指定cpu；<br>  cpu == -1: event绑定到所有cpu；  </p>
<p>  在同时指定的情况下task维度优先于cpu维度，所以pid、cpu组合起来有以下几种情况：<br>  <strong>组合1</strong>：pid &gt;= 0, cpu &gt;= 0。perf_event绑定到task维度的context。task在得到cpu调度运行的时候，context上挂载的本task相关的perf_event也开始运行。但是如果event指定的cpu不等于当前运行的cpu，event不会得到执行，这样就符合了这个组合的含义；<br>  <strong>组合2</strong>：pid &gt;= 0, cpu == -1。perf_event绑定到task维度的context。只要task得到调度，该perf_event就会得到执行；<br>  <strong>组合3</strong>：pid == -1, cpu &gt;= 0。perf_event绑定到cpu维度的context。只要该cpu运行，该perf_event就会得到执行。目前只有在cpu online的情况下才能绑定perf_event，cpu hotplug支持可能会有问题；<br>  <strong>组合4</strong>：pid == -1, cpu == -1。这种组合目前是非法的，相当于整系统所有cpu、所有进程。</p>
</li>
<li><p>4、<strong>group leader</strong>：</p>
<p>  cpu/task context使用-&gt;event_list链表来连接所有的perf_event。这些perf_event还允许以group的形式来组织，context使用-&gt;pinned_groups/flexible_groups链表来连接group leader的perf_event；group leader使用-&gt;sibling_list链表来连接所有的group member perf_event。组织形式参考上图。  </p>
<p>  group的作用是在read count的时候可以一次性读出group中所有perf_event的count。  </p>
<p>  perf_event_open()系统调用使用group_fd参数来指定perf_event的group_leader：&gt;=0指定对于的perf_event为当前group_leader，== -1创建新的group_leader。  </p>
<p>  <strong>pinned</strong>：可以看到group leader被放到两个链表中(-&gt;pinned_groups/flexible_groups)，attr.pinned=1指定放到高优先级链表-&gt;pinned_groups中。</p>
<p>  (具体参见后面perf_install_in_context()的代码解析)</p>
</li>
<li><p>5、<strong>perf_task_sched</strong>。</p>
<p>  对于cpu维度的perf_event来说只要cpu online会一直运行，而对于task维度的perf_event来说只有在task得到调度运行的时候event才能运行。所以在每个cpu上同时只能有一个task维度的perf_evnt得到执行，cpu维度的context使用了pmu-&gt;pmu_cpu_context-&gt;task_ctx指针来保存当前运行的task context。</p>
<p>  <img src="/images/perf_k/perf_k_perf_task_sched.png" alt="perf_k_perf_task_sched">  </p>
<p>  perf驱动层的<strong>精髓</strong>就在于此：在合适的时间合适的开关对应的perf_event。(具体参见后面perf_event_task_sched_in()、perf_event_task_sched_out()的代码解析)  </p>
<p>  在单个cpu上，多个任务调度时context/perf_event的开关情况：</p>
<p>  <img src="/images/perf_k/perf_k_perf_task_sched_time_on_onecpu.png" alt="perf_k_perf_task_sched_time_on_onecpu"></p>
<p>  单个任务，在多个cpu上调度时context/perf_event的开关情况：</p>
<p>  <img src="(/images/perf_k/perf_k_perf_task_sched_time_on_multicpu.png" alt="perf_k_perf_task_sched_time_on_multicpu"></p>
</li>
</ul>
<ul>
<li><p>6、<strong>inherit</strong>：</p>
<p>  inherit属性指定如果perf_event绑定的task创建子进程，event自动的对子进程也进行追踪。这在实际使用时是非常有用的，我们追踪一个app，随后它创建出的子进程/线程都能自动的被追踪。</p>
<p>  父进程中所有attr.inherit=1的event被子进程所继承和复制，在使用PERF_FORMAT_GROUP读event的count值时，会把inherit所有子进程的值累加进来。(具体参见后面perf_event_init_task()、perf_read_group()的代码解析)</p>
<p>  <img src="/images/perf_k/perf_k_event_task_inherit.png" alt="perf_k_event_task_inherit"></p>
</li>
<li><p>7、<strong>exclusive</strong>：</p>
<p>  如果pmu有PERF_PMU_CAP_EXCLUSIVE属性，表明它要么只能被绑定为cpu维度、要么只能被绑定为task维度，不能混合绑定。(具体参见后面exclusive_event_init()的代码解析)</p>
</li>
<li><p>8、pmu的数据供给：</p>
<p>  每个pmu拥有一个per_cpu的链表，perf_event需要在哪个cpu上获取数据就加入到哪个cpu的链表上。如果event被触发，它会根据当前的运行cpu给对应链表上的所有perf_event推送数据。</p>
<p>  cpu维度的context：this_cpu_ptr(pmu-&gt;pmu_cpu_context-&gt;ctx)上链接的所有perf_event会根据绑定的pmu，链接到pmu对应的per_cpu的-&gt;perf_events链表上。<br>  task维度的context：this_cpu_ptr(pmu-&gt;pmu_cpu_context-&gt;task_ctx)上链接的所有perf_event会根据绑定的pmu，链接到pmu对应的per_cpu的-&gt;perf_events链表上。perf_event还需要做cpu匹配，符合(event-&gt;cpu == -1 || event-&gt;cpu == smp_processor_id())条件的event才能链接到pmu上。</p>
<p>  <img src="/images/perf_k/perf_k_event_pmu_provide_data.png" alt="perf_k_event_pmu_provide_data"></p>
</li>
<li><p>9、<strong>enable_on_exec</strong>：</p>
<p>  perf_event的状态(event-&gt;state)典型值有以下3种：<br>  disable：PERF_EVENT_STATE_OFF        = -1,   // 如果attr.disabled = 1，event-&gt;state的初始值<br>  enable/inactive：PERF_EVENT_STATE_INACTIVE    =  0,   // 如果attr.disabled = 0，event-&gt;state的初始值<br>  active：PERF_EVENT_STATE_ACTIVE        =  1,     </p>
<p>  attr.disabled属性决定了perf_event的初始化状态(disable/enable)。只有perf_event为enable以后才能参与schedule，在schedule过程中perf_event被使能时为active，关闭后恢复成enbale/inactive状态。</p>
<p>  perf_event变成enable状态有3种方法：<br>  1、attr.disabled = 0；<br>  2、attr.disabled = 1，创建后使用ioctl的PERF_EVENT_IOC_ENABLE命令来使能；<br>  3、attr.disabled = 1，attr.enable_on_exec = 1。这样使用execl执行新程序时使能event，这是一种非常巧妙的同步手段；</p>
</li>
<li><p>10、<strong>ringbuffer</strong>:</p>
<p>  如果需要读取perf_event的sample类型的数据，需要先给perf_event分配一个对应的ringbuffer，为了减少开销这个ringbuffer会被mmap映射成用户态地址。</p>
<p>  如上图所示整个ringbuffer空间分成3部分：<br>  head：size = 1 page。主要用来存储控制数据，指针等等<br>  data：size = 2^n pages。主要用来存储perf_event的sample数据<br>  aux data：size = 2^n pages。作用暂时没有看明白</p>
<p>  如果perf_event支持inherit属性，那么它所有的子进程上继承的perf_event的sample数据，都会保存到父perf_event的ringbuffer中。perf_event可以inherit，但是ringbuffer不会重新分配，会共用父event的ringbuffer。</p>
<p>  <img src="/images/perf_k/perf_k_event_ringbuffer.png" alt="perf_k_event_ringbuffer"></p>
</li>
<li><p>11、<strong>sample_period/sample_freq</strong>:</p>
</li>
</ul>
<h1 id="1、perf-event初始化"><a href="#1、perf-event初始化" class="headerlink" title="1、perf_event初始化"></a>1、perf_event初始化</h1><p>perf_event初始化的时候将各种pmu注册到pmus链表。</p>
<p>start_kernel() -&gt; perf_event_init()：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line">void __init perf_event_init(void)</span><br><span class="line">&#123;</span><br><span class="line">	int ret;</span><br><span class="line"></span><br><span class="line">    /* (1) 初始化idr，给动态type的pmu来分配 */</span><br><span class="line">	idr_init(&amp;pmu_idr);</span><br><span class="line"></span><br><span class="line">    /* (2) 初始化per_cpu变量swevent_htable */</span><br><span class="line">	perf_event_init_all_cpus();</span><br><span class="line">	init_srcu_struct(&amp;pmus_srcu);</span><br><span class="line">	</span><br><span class="line">	/* (3) 注册&quot;software&quot; pmu */</span><br><span class="line">	perf_pmu_register(&amp;perf_swevent, &quot;software&quot;, PERF_TYPE_SOFTWARE);</span><br><span class="line">	perf_pmu_register(&amp;perf_cpu_clock, NULL, -1);</span><br><span class="line">	perf_pmu_register(&amp;perf_task_clock, NULL, -1);</span><br><span class="line">	</span><br><span class="line">	/* (4) 注册&quot;tracepoint&quot; pmu */</span><br><span class="line">	perf_tp_register();</span><br><span class="line">	perf_cpu_notifier(perf_cpu_notify);</span><br><span class="line">	idle_notifier_register(&amp;perf_event_idle_nb);</span><br><span class="line">	register_reboot_notifier(&amp;perf_reboot_notifier);</span><br><span class="line"></span><br><span class="line">    /* (5) 注册&quot;breakpoint&quot; pmu */</span><br><span class="line">	ret = init_hw_breakpoint();</span><br><span class="line">	WARN(ret, &quot;hw_breakpoint initialization failed with: %d&quot;, ret);</span><br><span class="line"></span><br><span class="line">	/* do not patch jump label more than once per second */</span><br><span class="line">	jump_label_rate_limit(&amp;perf_sched_events, HZ);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Build time assertion that we keep the data_head at the intended</span><br><span class="line">	 * location.  IOW, validation we got the __reserved[] size right.</span><br><span class="line">	 */</span><br><span class="line">	BUILD_BUG_ON((offsetof(struct perf_event_mmap_page, data_head))</span><br><span class="line">		     != 1024);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">↓</span><br><span class="line"></span><br><span class="line">int perf_pmu_register(struct pmu *pmu, const char *name, int type)</span><br><span class="line">&#123;</span><br><span class="line">	int cpu, ret;</span><br><span class="line"></span><br><span class="line">	mutex_lock(&amp;pmus_lock);</span><br><span class="line">	ret = -ENOMEM;</span><br><span class="line">	pmu-&gt;pmu_disable_count = alloc_percpu(int);</span><br><span class="line">	if (!pmu-&gt;pmu_disable_count)</span><br><span class="line">		goto unlock;</span><br><span class="line"></span><br><span class="line">    /* (3.1) 如果name = null，则pmu-&gt;name=null、pmu-&gt;type=-1 */</span><br><span class="line">	pmu-&gt;type = -1;</span><br><span class="line">	if (!name)</span><br><span class="line">		goto skip_type;</span><br><span class="line">	</span><br><span class="line">	/* (3.1.1) pmu-&gt;name = name */</span><br><span class="line">	pmu-&gt;name = name;</span><br><span class="line"></span><br><span class="line">    /* (3.1.2) 如果type &lt; 0，在idr中动态分配值给pmu-&gt;type */</span><br><span class="line">	if (type &lt; 0) &#123;</span><br><span class="line">		type = idr_alloc(&amp;pmu_idr, pmu, PERF_TYPE_MAX, 0, GFP_KERNEL);</span><br><span class="line">		if (type &lt; 0) &#123;</span><br><span class="line">			ret = type;</span><br><span class="line">			goto free_pdc;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	pmu-&gt;type = type;</span><br><span class="line"></span><br><span class="line">	if (pmu_bus_running) &#123;</span><br><span class="line">		ret = pmu_dev_alloc(pmu);</span><br><span class="line">		if (ret)</span><br><span class="line">			goto free_idr;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (3.2) 初始化cpu维度的perf_cpu_context，</span><br><span class="line">       perf_cpu_context的作用是用来把某一维度的perf_event链接到一起 </span><br><span class="line">     */</span><br><span class="line">skip_type:</span><br><span class="line">    /* (3.2.1) 如果有相同task_ctx_nr类型的pmu已经创建perf_cpu_context结构， </span><br><span class="line">        直接引用</span><br><span class="line">     */</span><br><span class="line">	pmu-&gt;pmu_cpu_context = find_pmu_context(pmu-&gt;task_ctx_nr);</span><br><span class="line">	if (pmu-&gt;pmu_cpu_context)</span><br><span class="line">		goto got_cpu_context;</span><br><span class="line"></span><br><span class="line">	ret = -ENOMEM;</span><br><span class="line">	/* (3.2.2) 如果没有人创建本pmu task_ctx_nr类型的perf_cpu_context结构， </span><br><span class="line">        重新创建</span><br><span class="line">     */</span><br><span class="line">	pmu-&gt;pmu_cpu_context = alloc_percpu(struct perf_cpu_context);</span><br><span class="line">	if (!pmu-&gt;pmu_cpu_context)</span><br><span class="line">		goto free_dev;</span><br><span class="line"></span><br><span class="line">    /* (3.2.3) 初始化per_cpu的perf_cpu_context结构 */</span><br><span class="line">	for_each_possible_cpu(cpu) &#123;</span><br><span class="line">		struct perf_cpu_context *cpuctx;</span><br><span class="line"></span><br><span class="line">		cpuctx = per_cpu_ptr(pmu-&gt;pmu_cpu_context, cpu);</span><br><span class="line">		__perf_event_init_context(&amp;cpuctx-&gt;ctx);</span><br><span class="line">		lockdep_set_class(&amp;cpuctx-&gt;ctx.mutex, &amp;cpuctx_mutex);</span><br><span class="line">		lockdep_set_class(&amp;cpuctx-&gt;ctx.lock, &amp;cpuctx_lock);</span><br><span class="line">		cpuctx-&gt;ctx.pmu = pmu;</span><br><span class="line"></span><br><span class="line">		__perf_mux_hrtimer_init(cpuctx, cpu);</span><br><span class="line"></span><br><span class="line">		cpuctx-&gt;unique_pmu = pmu;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">got_cpu_context:</span><br><span class="line">    /* (3.3) 给pmu赋值一些默认的操作函数 */</span><br><span class="line">	if (!pmu-&gt;start_txn) &#123;</span><br><span class="line">		if (pmu-&gt;pmu_enable) &#123;</span><br><span class="line">			/*</span><br><span class="line">			 * If we have pmu_enable/pmu_disable calls, install</span><br><span class="line">			 * transaction stubs that use that to try and batch</span><br><span class="line">			 * hardware accesses.</span><br><span class="line">			 */</span><br><span class="line">			pmu-&gt;start_txn  = perf_pmu_start_txn;</span><br><span class="line">			pmu-&gt;commit_txn = perf_pmu_commit_txn;</span><br><span class="line">			pmu-&gt;cancel_txn = perf_pmu_cancel_txn;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			pmu-&gt;start_txn  = perf_pmu_nop_txn;</span><br><span class="line">			pmu-&gt;commit_txn = perf_pmu_nop_int;</span><br><span class="line">			pmu-&gt;cancel_txn = perf_pmu_nop_void;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (!pmu-&gt;pmu_enable) &#123;</span><br><span class="line">		pmu-&gt;pmu_enable  = perf_pmu_nop_void;</span><br><span class="line">		pmu-&gt;pmu_disable = perf_pmu_nop_void;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (!pmu-&gt;event_idx)</span><br><span class="line">		pmu-&gt;event_idx = perf_event_idx_default;</span><br><span class="line"></span><br><span class="line">    /* (3.4) 最重要的一步：将新的pmu加入到pmus链表中 */</span><br><span class="line">	list_add_rcu(&amp;pmu-&gt;entry, &amp;pmus);</span><br><span class="line">	atomic_set(&amp;pmu-&gt;exclusive_cnt, 0);</span><br><span class="line">	ret = 0;</span><br><span class="line">unlock:</span><br><span class="line">	mutex_unlock(&amp;pmus_lock);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line"></span><br><span class="line">free_dev:</span><br><span class="line">	device_del(pmu-&gt;dev);</span><br><span class="line">	put_device(pmu-&gt;dev);</span><br><span class="line"></span><br><span class="line">free_idr:</span><br><span class="line">	if (pmu-&gt;type &gt;= PERF_TYPE_MAX)</span><br><span class="line">		idr_remove(&amp;pmu_idr, pmu-&gt;type);</span><br><span class="line"></span><br><span class="line">free_pdc:</span><br><span class="line">	free_percpu(pmu-&gt;pmu_disable_count);</span><br><span class="line">	goto unlock;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外一个函数perf_event_sysfs_init()会在稍后的device_initcall中，为所有“pmu-&gt;name != null”的pmu创建对应的device：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">static int __init perf_event_sysfs_init(void)</span><br><span class="line">&#123;</span><br><span class="line">	struct pmu *pmu;</span><br><span class="line">	int ret;</span><br><span class="line"></span><br><span class="line">	mutex_lock(&amp;pmus_lock);</span><br><span class="line"></span><br><span class="line">    /* (1) 注册pmu_bus */</span><br><span class="line">	ret = bus_register(&amp;pmu_bus);</span><br><span class="line">	if (ret)</span><br><span class="line">		goto unlock;</span><br><span class="line"></span><br><span class="line">    /* (2) 遍历pmus链表，创建pmu对应的device */</span><br><span class="line">	list_for_each_entry(pmu, &amp;pmus, entry) &#123;</span><br><span class="line">	    /* 如果pmu-&gt;name = null或者pmu-&gt;type &lt; 0，不创建 */</span><br><span class="line">		if (!pmu-&gt;name || pmu-&gt;type &lt; 0)</span><br><span class="line">			continue;</span><br><span class="line"></span><br><span class="line">		ret = pmu_dev_alloc(pmu);</span><br><span class="line">		WARN(ret, &quot;Failed to register pmu: %s, reason %d\n&quot;, pmu-&gt;name, ret);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/* (3) 设置pmu_bus_running */</span><br><span class="line">	pmu_bus_running = 1;</span><br><span class="line">	ret = 0;</span><br><span class="line"></span><br><span class="line">unlock:</span><br><span class="line">	mutex_unlock(&amp;pmus_lock);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line">device_initcall(perf_event_sysfs_init);</span><br></pre></td></tr></table></figure>
<p>可以在/sys路径下看到对应的device：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> # ls /sys/bus/event_source/devices/</span><br><span class="line">armv8_pmuv3 software tracepoint</span><br></pre></td></tr></table></figure>
<h1 id="2、perf-event-open系统调用"><a href="#2、perf-event-open系统调用" class="headerlink" title="2、perf_event_open系统调用"></a>2、perf_event_open系统调用</h1><p>perf_event_open会创建event对应的perf_event结构，按照perf_event_attr参数把perf_event和对应的pmu以及perf_cpu_context(cpu维度/task维度)绑定，最后再把perf_event和perf_fops以及fd绑定，返回fd给系统进行文件操作。</p>
<p>理解perf_event_open系统调用先理解它的5个参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perf_event_open(struct perf_event_attr attr, pid_t pid, int cpu, int group_fd, unsigned long flags)</span><br></pre></td></tr></table></figure>
<ul>
<li>参数1、struct perf_event_attr attr。该参数是最复杂也是最重要的参数：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><span class="line">struct perf_event_attr &#123;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Major type: hardware/software/tracepoint/etc.</span><br><span class="line">	 */</span><br><span class="line">	/* (1) 指定pmu的type：</span><br><span class="line">	    enum perf_type_id &#123;</span><br><span class="line">        	PERF_TYPE_HARDWARE			= 0,</span><br><span class="line">        	PERF_TYPE_SOFTWARE			= 1,</span><br><span class="line">        	PERF_TYPE_TRACEPOINT			= 2,</span><br><span class="line">        	PERF_TYPE_HW_CACHE			= 3,</span><br><span class="line">        	PERF_TYPE_RAW				= 4,</span><br><span class="line">        	PERF_TYPE_BREAKPOINT			= 5,</span><br><span class="line">        </span><br><span class="line">        	PERF_TYPE_MAX,				</span><br><span class="line">        &#125;;</span><br><span class="line">	 */</span><br><span class="line">	__u32			type;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Size of the attr structure, for fwd/bwd compat.</span><br><span class="line">	 */</span><br><span class="line">	/* (2) 整个perf_event_attr结构体的size */</span><br><span class="line">	__u32			size;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Type specific configuration information.</span><br><span class="line">	 */</span><br><span class="line">	/* (3) 不同type的pmu，config的含义也不同：</span><br><span class="line">	    1、type = PERF_TYPE_HARDWARE：</span><br><span class="line">	        enum perf_hw_id &#123;</span><br><span class="line">            	PERF_COUNT_HW_CPU_CYCLES		= 0,</span><br><span class="line">            	PERF_COUNT_HW_INSTRUCTIONS		= 1,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_REFERENCES		= 2,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_MISSES		= 3,</span><br><span class="line">            	PERF_COUNT_HW_BRANCH_INSTRUCTIONS	= 4,</span><br><span class="line">            	PERF_COUNT_HW_BRANCH_MISSES		= 5,</span><br><span class="line">            	PERF_COUNT_HW_BUS_CYCLES		= 6,</span><br><span class="line">            	PERF_COUNT_HW_STALLED_CYCLES_FRONTEND	= 7,</span><br><span class="line">            	PERF_COUNT_HW_STALLED_CYCLES_BACKEND	= 8,</span><br><span class="line">            	PERF_COUNT_HW_REF_CPU_CYCLES		= 9,</span><br><span class="line">            </span><br><span class="line">            	PERF_COUNT_HW_MAX,			</span><br><span class="line">            &#125;;</span><br><span class="line">	    2、type = PERF_TYPE_SOFTWARE：</span><br><span class="line">	        enum perf_sw_ids &#123;</span><br><span class="line">            	PERF_COUNT_SW_CPU_CLOCK			= 0,</span><br><span class="line">            	PERF_COUNT_SW_TASK_CLOCK		= 1,</span><br><span class="line">            	PERF_COUNT_SW_PAGE_FAULTS		= 2,</span><br><span class="line">            	PERF_COUNT_SW_CONTEXT_SWITCHES		= 3,</span><br><span class="line">            	PERF_COUNT_SW_CPU_MIGRATIONS		= 4,</span><br><span class="line">            	PERF_COUNT_SW_PAGE_FAULTS_MIN		= 5,</span><br><span class="line">            	PERF_COUNT_SW_PAGE_FAULTS_MAJ		= 6,</span><br><span class="line">            	PERF_COUNT_SW_ALIGNMENT_FAULTS		= 7,</span><br><span class="line">            	PERF_COUNT_SW_EMULATION_FAULTS		= 8,</span><br><span class="line">            	PERF_COUNT_SW_DUMMY			= 9,</span><br><span class="line">            	PERF_COUNT_SW_BPF_OUTPUT		= 10,</span><br><span class="line">            </span><br><span class="line">            	PERF_COUNT_SW_MAX,			</span><br><span class="line">            &#125;;</span><br><span class="line">	    3、type = PERF_TYPE_TRACEPOINT：</span><br><span class="line">	        trace_point对应trace_event的id：“/sys/kernel/debug/tracing/events/x/x/id”</span><br><span class="line">	    4、type = PERF_TYPE_HW_CACHE：</span><br><span class="line">	        enum perf_hw_cache_id &#123;</span><br><span class="line">            	PERF_COUNT_HW_CACHE_L1D			= 0,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_L1I			= 1,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_LL			= 2,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_DTLB		= 3,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_ITLB		= 4,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_BPU			= 5,</span><br><span class="line">            	PERF_COUNT_HW_CACHE_NODE		= 6,</span><br><span class="line">            </span><br><span class="line">            	PERF_COUNT_HW_CACHE_MAX,		</span><br><span class="line">            &#125;;</span><br><span class="line">	 */</span><br><span class="line">	__u64			config;</span><br><span class="line"></span><br><span class="line">    /* (4) period/freq sample模式的具体数值 */</span><br><span class="line">	union &#123;</span><br><span class="line">		__u64		sample_period;</span><br><span class="line">		__u64		sample_freq;</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">    /* (5) 在sample数据时，需要保存哪些数据：</span><br><span class="line">        enum perf_event_sample_format &#123;</span><br><span class="line">        	PERF_SAMPLE_IP				= 1U &lt;&lt; 0,</span><br><span class="line">        	PERF_SAMPLE_TID				= 1U &lt;&lt; 1,</span><br><span class="line">        	PERF_SAMPLE_TIME			= 1U &lt;&lt; 2,</span><br><span class="line">        	PERF_SAMPLE_ADDR			= 1U &lt;&lt; 3,</span><br><span class="line">        	PERF_SAMPLE_READ			= 1U &lt;&lt; 4,</span><br><span class="line">        	PERF_SAMPLE_CALLCHAIN			= 1U &lt;&lt; 5,</span><br><span class="line">        	PERF_SAMPLE_ID				= 1U &lt;&lt; 6,</span><br><span class="line">        	PERF_SAMPLE_CPU				= 1U &lt;&lt; 7,</span><br><span class="line">        	PERF_SAMPLE_PERIOD			= 1U &lt;&lt; 8,</span><br><span class="line">        	PERF_SAMPLE_STREAM_ID			= 1U &lt;&lt; 9,</span><br><span class="line">        	PERF_SAMPLE_RAW				= 1U &lt;&lt; 10,</span><br><span class="line">        	PERF_SAMPLE_BRANCH_STACK		= 1U &lt;&lt; 11,</span><br><span class="line">        	PERF_SAMPLE_REGS_USER			= 1U &lt;&lt; 12,</span><br><span class="line">        	PERF_SAMPLE_STACK_USER			= 1U &lt;&lt; 13,</span><br><span class="line">        	PERF_SAMPLE_WEIGHT			= 1U &lt;&lt; 14,</span><br><span class="line">        	PERF_SAMPLE_DATA_SRC			= 1U &lt;&lt; 15,</span><br><span class="line">        	PERF_SAMPLE_IDENTIFIER			= 1U &lt;&lt; 16,</span><br><span class="line">        	PERF_SAMPLE_TRANSACTION			= 1U &lt;&lt; 17,</span><br><span class="line">        	PERF_SAMPLE_REGS_INTR			= 1U &lt;&lt; 18,</span><br><span class="line">        </span><br><span class="line">        	PERF_SAMPLE_MAX = 1U &lt;&lt; 19,	</span><br><span class="line">        &#125;;</span><br><span class="line">     */</span><br><span class="line">	__u64			sample_type;</span><br><span class="line">	</span><br><span class="line">	/* (6) 在read counter数据时，读取的格式:</span><br><span class="line">	     *</span><br><span class="line">         * The format of the data returned by read() on a perf event fd,</span><br><span class="line">         * as specified by attr.read_format:</span><br><span class="line">         *</span><br><span class="line">         * struct read_format &#123;</span><br><span class="line">         *	&#123; u64		value;</span><br><span class="line">         *	  &#123; u64		time_enabled; &#125; &amp;&amp; PERF_FORMAT_TOTAL_TIME_ENABLED</span><br><span class="line">         *	  &#123; u64		time_running; &#125; &amp;&amp; PERF_FORMAT_TOTAL_TIME_RUNNING</span><br><span class="line">         *	  &#123; u64		id;           &#125; &amp;&amp; PERF_FORMAT_ID</span><br><span class="line">         *	&#125; &amp;&amp; !PERF_FORMAT_GROUP</span><br><span class="line">         *</span><br><span class="line">         *	&#123; u64		nr;</span><br><span class="line">         *	  &#123; u64		time_enabled; &#125; &amp;&amp; PERF_FORMAT_TOTAL_TIME_ENABLED</span><br><span class="line">         *	  &#123; u64		time_running; &#125; &amp;&amp; PERF_FORMAT_TOTAL_TIME_RUNNING</span><br><span class="line">         *	  &#123; u64		value;</span><br><span class="line">         *	    &#123; u64	id;           &#125; &amp;&amp; PERF_FORMAT_ID</span><br><span class="line">         *	  &#125;		cntr[nr];</span><br><span class="line">         *	&#125; &amp;&amp; PERF_FORMAT_GROUP</span><br><span class="line">         * &#125;;</span><br><span class="line">         *</span><br><span class="line">        enum perf_event_read_format &#123;</span><br><span class="line">        	PERF_FORMAT_TOTAL_TIME_ENABLED		= 1U &lt;&lt; 0,</span><br><span class="line">        	PERF_FORMAT_TOTAL_TIME_RUNNING		= 1U &lt;&lt; 1,</span><br><span class="line">        	PERF_FORMAT_ID				= 1U &lt;&lt; 2,</span><br><span class="line">        	PERF_FORMAT_GROUP			= 1U &lt;&lt; 3,</span><br><span class="line">        </span><br><span class="line">        	PERF_FORMAT_MAX = 1U &lt;&lt; 4,		</span><br><span class="line">        &#125;;</span><br><span class="line">	 */</span><br><span class="line">	__u64			read_format;</span><br><span class="line"></span><br><span class="line">    /* (7) bit标志 */</span><br><span class="line">                /* (7.1) 定义event的初始状态为disable/enable。</span><br><span class="line">                    如果初始被disable，后续可以通过ioctl/prctl来enable。 </span><br><span class="line">                 */</span><br><span class="line">	__u64			disabled       :  1, /* off by default        */</span><br><span class="line">	</span><br><span class="line">	            /* (7.2) 如果该标志被设置，event进程对应的子孙后代的子进程都会计入counter */</span><br><span class="line">				inherit	       :  1, /* children inherit it   */</span><br><span class="line">				</span><br><span class="line">				/* (7.3) 如果该标志被设置，event和cpu绑定。(只适用于硬件counter只适用于group leaders) */</span><br><span class="line">				pinned	       :  1, /* must always be on PMU */</span><br><span class="line">				</span><br><span class="line">				/* (7.4) 如果该标志被设置，指定当这个group在CPU上时，它应该是唯一使用CPU计数器的group */</span><br><span class="line">				exclusive      :  1, /* only group on PMU     */</span><br><span class="line">				</span><br><span class="line">				/* (7.5) exclude_user/exclude_kernel/exclude_hv/exclude_idle这几个标志用来标识，</span><br><span class="line">				    不要记录对应场景的数据</span><br><span class="line">				 */</span><br><span class="line">				exclude_user   :  1, /* don&apos;t count user      */</span><br><span class="line">				exclude_kernel :  1, /* ditto kernel          */</span><br><span class="line">				exclude_hv     :  1, /* ditto hypervisor      */</span><br><span class="line">				exclude_idle   :  1, /* don&apos;t count when idle */</span><br><span class="line">				</span><br><span class="line">				/* (7.6) 允许记录PROT_EXEC mmap操作 */</span><br><span class="line">				mmap           :  1, /* include mmap data     */</span><br><span class="line">				</span><br><span class="line">				/* (7.7) 允许记录进程创建时的comm数据 */</span><br><span class="line">				comm	       :  1, /* include comm data     */</span><br><span class="line">				</span><br><span class="line">				/* (7.8) 确定sample模式 = freq/period */</span><br><span class="line">				freq           :  1, /* use freq, not period  */</span><br><span class="line">				</span><br><span class="line">				</span><br><span class="line">				inherit_stat   :  1, /* per task counts       */</span><br><span class="line">				enable_on_exec :  1, /* next exec enables     */</span><br><span class="line">				task           :  1, /* trace fork/exit       */</span><br><span class="line">				watermark      :  1, /* wakeup_watermark      */</span><br><span class="line">				/*</span><br><span class="line">				 * precise_ip:</span><br><span class="line">				 *</span><br><span class="line">				 *  0 - SAMPLE_IP can have arbitrary skid</span><br><span class="line">				 *  1 - SAMPLE_IP must have constant skid</span><br><span class="line">				 *  2 - SAMPLE_IP requested to have 0 skid</span><br><span class="line">				 *  3 - SAMPLE_IP must have 0 skid</span><br><span class="line">				 *</span><br><span class="line">				 *  See also PERF_RECORD_MISC_EXACT_IP</span><br><span class="line">				 */</span><br><span class="line">				precise_ip     :  2, /* skid constraint       */</span><br><span class="line">				mmap_data      :  1, /* non-exec mmap data    */</span><br><span class="line">				sample_id_all  :  1, /* sample_type all events */</span><br><span class="line"></span><br><span class="line">				exclude_host   :  1, /* don&apos;t count in host   */</span><br><span class="line">				exclude_guest  :  1, /* don&apos;t count in guest  */</span><br><span class="line"></span><br><span class="line">				exclude_callchain_kernel : 1, /* exclude kernel callchains */</span><br><span class="line">				exclude_callchain_user   : 1, /* exclude user callchains */</span><br><span class="line">				mmap2          :  1, /* include mmap with inode data     */</span><br><span class="line">				comm_exec      :  1, /* flag comm events that are due to an exec */</span><br><span class="line">				use_clockid    :  1, /* use @clockid for time fields */</span><br><span class="line">				context_switch :  1, /* context switch data */</span><br><span class="line">				constraint_duplicate : 1,</span><br><span class="line"></span><br><span class="line">				__reserved_1   : 36;</span><br><span class="line"></span><br><span class="line">	union &#123;</span><br><span class="line">		__u32		wakeup_events;	  /* wakeup every n events */</span><br><span class="line">		__u32		wakeup_watermark; /* bytes before wakeup   */</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	__u32			bp_type;</span><br><span class="line">	union &#123;</span><br><span class="line">		__u64		bp_addr;</span><br><span class="line">		__u64		config1; /* extension of config */</span><br><span class="line">	&#125;;</span><br><span class="line">	union &#123;</span><br><span class="line">		__u64		bp_len;</span><br><span class="line">		__u64		config2; /* extension of config1 */</span><br><span class="line">	&#125;;</span><br><span class="line">	__u64	branch_sample_type; /* enum perf_branch_sample_type */</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Defines set of user regs to dump on samples.</span><br><span class="line">	 * See asm/perf_regs.h for details.</span><br><span class="line">	 */</span><br><span class="line">	__u64	sample_regs_user;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Defines size of the user stack to dump on samples.</span><br><span class="line">	 */</span><br><span class="line">	__u32	sample_stack_user;</span><br><span class="line"></span><br><span class="line">	__s32	clockid;</span><br><span class="line">	/*</span><br><span class="line">	 * Defines set of regs to dump for each sample</span><br><span class="line">	 * state captured on:</span><br><span class="line">	 *  - precise = 0: PMU interrupt</span><br><span class="line">	 *  - precise &gt; 0: sampled instruction</span><br><span class="line">	 *</span><br><span class="line">	 * See asm/perf_regs.h for details.</span><br><span class="line">	 */</span><br><span class="line">	__u64	sample_regs_intr;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Wakeup watermark for AUX area</span><br><span class="line">	 */</span><br><span class="line">	__u32	aux_watermark;</span><br><span class="line">	__u32	__reserved_2;	/* align to __u64 */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>参数2、pid_t pid：</p>
<p>  pid == 0: event绑定到当前进程；<br>  pid &gt; 0: event绑定到指定进程；<br>  pid &lt; 0: event绑定到当前cpu的所有进程。</p>
</li>
<li><p>参数3、int cpu：</p>
<p>  cpu &gt;= 0: event绑定到指定cpu；<br>  cpu == -1: event绑定到所有cpu；<br>  (注意’pid == -1’、’cpu == -1’同时存在是非法的)</p>
</li>
<li><p>参数4、int group_fd：</p>
<p>  group_fd = -1：创建一个新的group leader；<br>  group_fd &gt; 0：加入到之前创建的group leader中。</p>
</li>
<li><p>参数5、unsigned long flags：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define PERF_FLAG_FD_NO_GROUP		(1UL &lt;&lt; 0)</span><br><span class="line">#define PERF_FLAG_FD_OUTPUT		(1UL &lt;&lt; 1)</span><br><span class="line">#define PERF_FLAG_PID_CGROUP		(1UL &lt;&lt; 2) /* pid=cgroup id, per-cpu mode only */</span><br><span class="line">#define PERF_FLAG_FD_CLOEXEC		(1UL &lt;&lt; 3) /* O_CLOEXEC */</span><br></pre></td></tr></table></figure>
<p>perf_event_open()函数的完全解析如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br><span class="line">819</span><br><span class="line">820</span><br><span class="line">821</span><br><span class="line">822</span><br><span class="line">823</span><br><span class="line">824</span><br><span class="line">825</span><br><span class="line">826</span><br><span class="line">827</span><br><span class="line">828</span><br><span class="line">829</span><br><span class="line">830</span><br><span class="line">831</span><br><span class="line">832</span><br><span class="line">833</span><br><span class="line">834</span><br><span class="line">835</span><br><span class="line">836</span><br><span class="line">837</span><br><span class="line">838</span><br><span class="line">839</span><br><span class="line">840</span><br><span class="line">841</span><br><span class="line">842</span><br><span class="line">843</span><br><span class="line">844</span><br><span class="line">845</span><br><span class="line">846</span><br><span class="line">847</span><br><span class="line">848</span><br><span class="line">849</span><br><span class="line">850</span><br><span class="line">851</span><br><span class="line">852</span><br><span class="line">853</span><br><span class="line">854</span><br><span class="line">855</span><br><span class="line">856</span><br><span class="line">857</span><br><span class="line">858</span><br><span class="line">859</span><br><span class="line">860</span><br><span class="line">861</span><br><span class="line">862</span><br><span class="line">863</span><br><span class="line">864</span><br><span class="line">865</span><br><span class="line">866</span><br><span class="line">867</span><br><span class="line">868</span><br><span class="line">869</span><br><span class="line">870</span><br><span class="line">871</span><br><span class="line">872</span><br><span class="line">873</span><br><span class="line">874</span><br><span class="line">875</span><br><span class="line">876</span><br><span class="line">877</span><br><span class="line">878</span><br><span class="line">879</span><br><span class="line">880</span><br><span class="line">881</span><br><span class="line">882</span><br><span class="line">883</span><br><span class="line">884</span><br><span class="line">885</span><br><span class="line">886</span><br><span class="line">887</span><br><span class="line">888</span><br><span class="line">889</span><br><span class="line">890</span><br><span class="line">891</span><br><span class="line">892</span><br><span class="line">893</span><br><span class="line">894</span><br><span class="line">895</span><br><span class="line">896</span><br><span class="line">897</span><br><span class="line">898</span><br><span class="line">899</span><br><span class="line">900</span><br><span class="line">901</span><br><span class="line">902</span><br><span class="line">903</span><br><span class="line">904</span><br><span class="line">905</span><br><span class="line">906</span><br><span class="line">907</span><br><span class="line">908</span><br><span class="line">909</span><br><span class="line">910</span><br><span class="line">911</span><br><span class="line">912</span><br><span class="line">913</span><br><span class="line">914</span><br><span class="line">915</span><br></pre></td><td class="code"><pre><span class="line">SYSCALL_DEFINE5(perf_event_open,</span><br><span class="line">		struct perf_event_attr __user *, attr_uptr,</span><br><span class="line">		pid_t, pid, int, cpu, int, group_fd, unsigned long, flags)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *group_leader = NULL, *output_event = NULL;</span><br><span class="line">	struct perf_event *event, *sibling;</span><br><span class="line">	struct perf_event_attr attr;</span><br><span class="line">	struct perf_event_context *ctx, *uninitialized_var(gctx);</span><br><span class="line">	struct file *event_file = NULL;</span><br><span class="line">	struct fd group = &#123;NULL, 0&#125;;</span><br><span class="line">	struct task_struct *task = NULL;</span><br><span class="line">	struct pmu *pmu;</span><br><span class="line">	int event_fd;</span><br><span class="line">	int move_group = 0;</span><br><span class="line">	int err;</span><br><span class="line">	int f_flags = O_RDWR;</span><br><span class="line">	int cgroup_fd = -1;</span><br><span class="line"></span><br><span class="line">    /* (1) 一系列的合法性判断和准备工作 */</span><br><span class="line">	/* for future expandability... */</span><br><span class="line">	if (flags &amp; ~PERF_FLAG_ALL)</span><br><span class="line">		return -EINVAL;</span><br><span class="line"></span><br><span class="line">    /* (1.1) 权限判断 */</span><br><span class="line">	if (perf_paranoid_any() &amp;&amp; !capable(CAP_SYS_ADMIN))</span><br><span class="line">		return -EACCES;</span><br><span class="line"></span><br><span class="line">    /* (1.2) 拷贝用户态的perf_event_attr到内核态 */</span><br><span class="line">	err = perf_copy_attr(attr_uptr, &amp;attr);</span><br><span class="line">	if (err)</span><br><span class="line">		return err;</span><br><span class="line"></span><br><span class="line">	if (attr.constraint_duplicate || attr.__reserved_1)</span><br><span class="line">		return -EINVAL;</span><br><span class="line"></span><br><span class="line">	if (!attr.exclude_kernel) &#123;</span><br><span class="line">		if (perf_paranoid_kernel() &amp;&amp; !capable(CAP_SYS_ADMIN))</span><br><span class="line">			return -EACCES;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (1.3) 如果sample是freq mode，sample_freq的合法性判断 */</span><br><span class="line">	if (attr.freq) &#123;</span><br><span class="line">		if (attr.sample_freq &gt; sysctl_perf_event_sample_rate)</span><br><span class="line">			return -EINVAL;</span><br><span class="line">	/* (1.4) 如果sample是period mode，sample_period的合法性判断 */</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		if (attr.sample_period &amp; (1ULL &lt;&lt; 63))</span><br><span class="line">			return -EINVAL;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * In cgroup mode, the pid argument is used to pass the fd</span><br><span class="line">	 * opened to the cgroup directory in cgroupfs. The cpu argument</span><br><span class="line">	 * designates the cpu on which to monitor threads from that</span><br><span class="line">	 * cgroup.</span><br><span class="line">	 */</span><br><span class="line">	if ((flags &amp; PERF_FLAG_PID_CGROUP) &amp;&amp; (pid == -1 || cpu == -1))</span><br><span class="line">		return -EINVAL;</span><br><span class="line"></span><br><span class="line">	if (flags &amp; PERF_FLAG_FD_CLOEXEC)</span><br><span class="line">		f_flags |= O_CLOEXEC;</span><br><span class="line"></span><br><span class="line">    /* (1.5) 当前进程获取一个新的fd编号  */</span><br><span class="line">	event_fd = get_unused_fd_flags(f_flags);</span><br><span class="line">	if (event_fd &lt; 0)</span><br><span class="line">		return event_fd;</span><br><span class="line"></span><br><span class="line">    /* (1.6) 如果当前event需要加入到指定的group leader中，获取到： </span><br><span class="line">        group_fd对应的fd结构 和 perf_event结构</span><br><span class="line">     */</span><br><span class="line">	if (group_fd != -1) &#123;</span><br><span class="line">		err = perf_fget_light(group_fd, &amp;group);</span><br><span class="line">		if (err)</span><br><span class="line">			goto err_fd;</span><br><span class="line">		group_leader = group.file-&gt;private_data;</span><br><span class="line">		if (flags &amp; PERF_FLAG_FD_OUTPUT)</span><br><span class="line">			output_event = group_leader;</span><br><span class="line">		if (flags &amp; PERF_FLAG_FD_NO_GROUP)</span><br><span class="line">			group_leader = NULL;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Take the group_leader&apos;s group_leader_mutex before observing</span><br><span class="line">	 * anything in the group leader that leads to changes in ctx,</span><br><span class="line">	 * many of which may be changing on another thread.</span><br><span class="line">	 * In particular, we want to take this lock before deciding</span><br><span class="line">	 * whether we need to move_group.</span><br><span class="line">	 */</span><br><span class="line">	if (group_leader)</span><br><span class="line">		mutex_lock(&amp;group_leader-&gt;group_leader_mutex);</span><br><span class="line"></span><br><span class="line">    /* (1.7) 找到pid对应的task_struct结构 */</span><br><span class="line">	if (pid != -1 &amp;&amp; !(flags &amp; PERF_FLAG_PID_CGROUP)) &#123;</span><br><span class="line">		task = find_lively_task_by_vpid(pid);</span><br><span class="line">		if (IS_ERR(task)) &#123;</span><br><span class="line">			err = PTR_ERR(task);</span><br><span class="line">			goto err_group_fd;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (1.8) 如果是加入到group leader，需要两者的attr.inherit属性一致 */</span><br><span class="line">	if (task &amp;&amp; group_leader &amp;&amp;</span><br><span class="line">	    group_leader-&gt;attr.inherit != attr.inherit) &#123;</span><br><span class="line">		err = -EINVAL;</span><br><span class="line">		goto err_task;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	get_online_cpus();</span><br><span class="line"></span><br><span class="line">	if (task) &#123;</span><br><span class="line">		err = mutex_lock_interruptible(&amp;task-&gt;signal-&gt;cred_guard_mutex);</span><br><span class="line">		if (err)</span><br><span class="line">			goto err_cpus;</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Reuse ptrace permission checks for now.</span><br><span class="line">		 *</span><br><span class="line">		 * We must hold cred_guard_mutex across this and any potential</span><br><span class="line">		 * perf_install_in_context() call for this new event to</span><br><span class="line">		 * serialize against exec() altering our credentials (and the</span><br><span class="line">		 * perf_event_exit_task() that could imply).</span><br><span class="line">		 */</span><br><span class="line">		err = -EACCES;</span><br><span class="line">		if (!ptrace_may_access(task, PTRACE_MODE_READ_REALCREDS))</span><br><span class="line">			goto err_cred;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (1.9) 创建cgroup fd，这和之前的group leader不一样 */</span><br><span class="line">	if (flags &amp; PERF_FLAG_PID_CGROUP)</span><br><span class="line">		cgroup_fd = pid;</span><br><span class="line"></span><br><span class="line">    /* (2) 重头戏：根据传入的参数，分配perf_event结构并初始化 */</span><br><span class="line">	event = perf_event_alloc(&amp;attr, cpu, task, group_leader, NULL,</span><br><span class="line">				 NULL, NULL, cgroup_fd);</span><br><span class="line">	if (IS_ERR(event)) &#123;</span><br><span class="line">		err = PTR_ERR(event);</span><br><span class="line">		goto err_cred;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (3.1) 如果attr指定需要sample数据，但是pmu没有中断能力，返回出错(主要是针对硬件pmu) */</span><br><span class="line">	if (is_sampling_event(event)) &#123;</span><br><span class="line">		if (event-&gt;pmu-&gt;capabilities &amp; PERF_PMU_CAP_NO_INTERRUPT) &#123;</span><br><span class="line">			err = -ENOTSUPP;</span><br><span class="line">			goto err_alloc;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Special case software events and allow them to be part of</span><br><span class="line">	 * any hardware group.</span><br><span class="line">	 */</span><br><span class="line">	pmu = event-&gt;pmu;</span><br><span class="line"></span><br><span class="line">    /* (3.2) 如果用户指定时钟源，把event-&gt;clock设置为用户指定值 */</span><br><span class="line">	if (attr.use_clockid) &#123;</span><br><span class="line">		err = perf_event_set_clock(event, attr.clockid);</span><br><span class="line">		if (err)</span><br><span class="line">			goto err_alloc;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (3.3) 如果event和group_leader的pmu type不一致的处理 */</span><br><span class="line">	if (group_leader &amp;&amp;</span><br><span class="line">	    (is_software_event(event) != is_software_event(group_leader))) &#123;</span><br><span class="line">	    /* (3.3.1) pmu type: event == software, group_leader != software </span><br><span class="line">	        把event加入到group_leader中</span><br><span class="line">	     */</span><br><span class="line">		if (is_software_event(event)) &#123;</span><br><span class="line">			/*</span><br><span class="line">			 * If event and group_leader are not both a software</span><br><span class="line">			 * event, and event is, then group leader is not.</span><br><span class="line">			 *</span><br><span class="line">			 * Allow the addition of software events to !software</span><br><span class="line">			 * groups, this is safe because software events never</span><br><span class="line">			 * fail to schedule.</span><br><span class="line">			 */</span><br><span class="line">			pmu = group_leader-&gt;pmu;</span><br><span class="line">			</span><br><span class="line">		/* (3.3.2) pmu type: event != software, group_leader == software </span><br><span class="line">	        尝试把整个group移入到hardware context中</span><br><span class="line">	     */</span><br><span class="line">		&#125; else if (is_software_event(group_leader) &amp;&amp;</span><br><span class="line">			   (group_leader-&gt;group_flags &amp; PERF_GROUP_SOFTWARE)) &#123;</span><br><span class="line">			/*</span><br><span class="line">			 * In case the group is a pure software group, and we</span><br><span class="line">			 * try to add a hardware event, move the whole group to</span><br><span class="line">			 * the hardware context.</span><br><span class="line">			 */</span><br><span class="line">			move_group = 1;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Get the target context (task or percpu):</span><br><span class="line">	 */</span><br><span class="line">	/* (4) get到perf_event_context，根据perf_event类型得到cpu维度/task维度的context：</span><br><span class="line">	    如果pid=-1即task=NULL，获得cpu维度的context，即pmu注册时根据pmu-&gt;task_ctx_nr分配的pmu-&gt;pmu_cpu_context-&gt;ctx</span><br><span class="line">	    如果pid&gt;=0即task!=NULL，获得task维度的context，即task-&gt;perf_event_ctxp[ctxn]，如果为空则重新创建</span><br><span class="line">	 */</span><br><span class="line">	ctx = find_get_context(pmu, task, event);</span><br><span class="line">	if (IS_ERR(ctx)) &#123;</span><br><span class="line">		err = PTR_ERR(ctx);</span><br><span class="line">		goto err_alloc;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (5.1) event需要加入到group_leader，如果(pmu-&gt;capabilities &amp; PERF_PMU_CAP_EXCLUSIVE)，出错返回  */</span><br><span class="line">	if ((pmu-&gt;capabilities &amp; PERF_PMU_CAP_EXCLUSIVE) &amp;&amp; group_leader) &#123;</span><br><span class="line">		err = -EBUSY;</span><br><span class="line">		goto err_context;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Look up the group leader (we will attach this event to it):</span><br><span class="line">	 */</span><br><span class="line">	/* (5.2) event需要加入到group_leader，对一些条件进行合法性判断  */</span><br><span class="line">	if (group_leader) &#123;</span><br><span class="line">		err = -EINVAL;</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Do not allow a recursive hierarchy (this new sibling</span><br><span class="line">		 * becoming part of another group-sibling):</span><br><span class="line">		 */</span><br><span class="line">		/* (5.2.1) 不允许递归的-&gt;group_leader */</span><br><span class="line">		if (group_leader-&gt;group_leader != group_leader)</span><br><span class="line">			goto err_context;</span><br><span class="line"></span><br><span class="line">		/* All events in a group should have the same clock */</span><br><span class="line">		/* (5.2.2) event加入gruop，需要时钟源一致 */</span><br><span class="line">		if (group_leader-&gt;clock != event-&gt;clock)</span><br><span class="line">			goto err_context;</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Do not allow to attach to a group in a different</span><br><span class="line">		 * task or CPU context:</span><br><span class="line">		 */</span><br><span class="line">		/* (5.2.3) event加入gruop，需要task/cpu的context一致 */</span><br><span class="line">		if (move_group) &#123;</span><br><span class="line">			/*</span><br><span class="line">			 * Make sure we&apos;re both on the same task, or both</span><br><span class="line">			 * per-cpu events.</span><br><span class="line">			 */</span><br><span class="line">			if (group_leader-&gt;ctx-&gt;task != ctx-&gt;task)</span><br><span class="line">				goto err_context;</span><br><span class="line"></span><br><span class="line">			/*</span><br><span class="line">			 * Make sure we&apos;re both events for the same CPU;</span><br><span class="line">			 * grouping events for different CPUs is broken; since</span><br><span class="line">			 * you can never concurrently schedule them anyhow.</span><br><span class="line">			 */</span><br><span class="line">			if (group_leader-&gt;cpu != event-&gt;cpu)</span><br><span class="line">				goto err_context;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			if (group_leader-&gt;ctx != ctx)</span><br><span class="line">				goto err_context;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Only a group leader can be exclusive or pinned</span><br><span class="line">		 */</span><br><span class="line">		/* (5.2.4) 只有group才能设置exclusive/pinned属性 */</span><br><span class="line">		if (attr.exclusive || attr.pinned)</span><br><span class="line">			goto err_context;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (5.3) 设置output_event */</span><br><span class="line">	if (output_event) &#123;</span><br><span class="line">		err = perf_event_set_output(event, output_event);</span><br><span class="line">		if (err)</span><br><span class="line">			goto err_context;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (6) 分配perf_event对应的file结构： </span><br><span class="line">        file-&gt;private_data = event; // file和event结构链接在一起</span><br><span class="line">        file-&gt;f_op = perf_fops；    // file的文件操作函数集</span><br><span class="line">        后续会把fd和file链接到一起：fd_install(event_fd, event_file);</span><br><span class="line">     */</span><br><span class="line">	event_file = anon_inode_getfile(&quot;[perf_event]&quot;, &amp;perf_fops, event,</span><br><span class="line">					f_flags);</span><br><span class="line">	if (IS_ERR(event_file)) &#123;</span><br><span class="line">		err = PTR_ERR(event_file);</span><br><span class="line">		event_file = NULL;</span><br><span class="line">		goto err_context;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (move_group) &#123;</span><br><span class="line">		gctx = group_leader-&gt;ctx;</span><br><span class="line">		mutex_lock_double(&amp;gctx-&gt;mutex, &amp;ctx-&gt;mutex);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		mutex_lock(&amp;ctx-&gt;mutex);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (7.1) 根据attr计算：event-&gt;read_size、event-&gt;header_size、event-&gt;id_header_size </span><br><span class="line">        并判断是否有超长</span><br><span class="line">     */</span><br><span class="line">	if (!perf_event_validate_size(event)) &#123;</span><br><span class="line">		err = -E2BIG;</span><br><span class="line">		goto err_locked;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Must be under the same ctx::mutex as perf_install_in_context(),</span><br><span class="line">	 * because we need to serialize with concurrent event creation.</span><br><span class="line">	 */</span><br><span class="line">	/* (7.2) 如果是排他性event：(pmu-&gt;capabilities &amp; PERF_PMU_CAP_EXCLUSIVE) </span><br><span class="line">	    检查context链表中现有的event是否允许新的event插入</span><br><span class="line">	 */</span><br><span class="line">	if (!exclusive_event_installable(event, ctx)) &#123;</span><br><span class="line">		/* exclusive and group stuff are assumed mutually exclusive */</span><br><span class="line">		WARN_ON_ONCE(move_group);</span><br><span class="line"></span><br><span class="line">		err = -EBUSY;</span><br><span class="line">		goto err_locked;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	WARN_ON_ONCE(ctx-&gt;parent_ctx);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * This is the point on no return; we cannot fail hereafter. This is</span><br><span class="line">	 * where we start modifying current state.</span><br><span class="line">	 */</span><br><span class="line"></span><br><span class="line">    /* (8) 如果group和当前event的pmu type不一致，</span><br><span class="line">        尝试更改context到当前event</span><br><span class="line">     */</span><br><span class="line">	if (move_group) &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * See perf_event_ctx_lock() for comments on the details</span><br><span class="line">		 * of swizzling perf_event::ctx.</span><br><span class="line">		 */</span><br><span class="line">		/* (8.1) 把group_leader从原有的context中remove */</span><br><span class="line">		perf_remove_from_context(group_leader, false);</span><br><span class="line"></span><br><span class="line">        /* (8.2) 把所有group_leader的子event从原有的context中remove */</span><br><span class="line">		list_for_each_entry(sibling, &amp;group_leader-&gt;sibling_list,</span><br><span class="line">				    group_entry) &#123;</span><br><span class="line">			perf_remove_from_context(sibling, false);</span><br><span class="line">			put_ctx(gctx);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Wait for everybody to stop referencing the events through</span><br><span class="line">		 * the old lists, before installing it on new lists.</span><br><span class="line">		 */</span><br><span class="line">		synchronize_rcu();</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Install the group siblings before the group leader.</span><br><span class="line">		 *</span><br><span class="line">		 * Because a group leader will try and install the entire group</span><br><span class="line">		 * (through the sibling list, which is still in-tact), we can</span><br><span class="line">		 * end up with siblings installed in the wrong context.</span><br><span class="line">		 *</span><br><span class="line">		 * By installing siblings first we NO-OP because they&apos;re not</span><br><span class="line">		 * reachable through the group lists.</span><br><span class="line">		 */</span><br><span class="line">		/* (8.3) 把所有group_leader的子event安装到新的context中 */</span><br><span class="line">		list_for_each_entry(sibling, &amp;group_leader-&gt;sibling_list,</span><br><span class="line">				    group_entry) &#123;</span><br><span class="line">			perf_event__state_init(sibling);</span><br><span class="line">			perf_install_in_context(ctx, sibling, sibling-&gt;cpu);</span><br><span class="line">			get_ctx(ctx);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Removing from the context ends up with disabled</span><br><span class="line">		 * event. What we want here is event in the initial</span><br><span class="line">		 * startup state, ready to be add into new context.</span><br><span class="line">		 */</span><br><span class="line">		/* (8.4) 把group_leader安装到新的context中 */</span><br><span class="line">		perf_event__state_init(group_leader);</span><br><span class="line">		perf_install_in_context(ctx, group_leader, group_leader-&gt;cpu);</span><br><span class="line">		get_ctx(ctx);</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * Now that all events are installed in @ctx, nothing</span><br><span class="line">		 * references @gctx anymore, so drop the last reference we have</span><br><span class="line">		 * on it.</span><br><span class="line">		 */</span><br><span class="line">		put_ctx(gctx);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Precalculate sample_data sizes; do while holding ctx::mutex such</span><br><span class="line">	 * that we&apos;re serialized against further additions and before</span><br><span class="line">	 * perf_install_in_context() which is the point the event is active and</span><br><span class="line">	 * can use these values.</span><br><span class="line">	 */</span><br><span class="line">	/* (9.1) 重新计算：event-&gt;read_size、event-&gt;header_size、event-&gt;id_header_size */</span><br><span class="line">	perf_event__header_size(event);</span><br><span class="line">	perf_event__id_header_size(event);</span><br><span class="line"></span><br><span class="line">    /* (10) 把event安装到context当中 */</span><br><span class="line">	perf_install_in_context(ctx, event, event-&gt;cpu);</span><br><span class="line">	perf_unpin_context(ctx);</span><br><span class="line"></span><br><span class="line">	if (move_group)</span><br><span class="line">		mutex_unlock(&amp;gctx-&gt;mutex);</span><br><span class="line">	mutex_unlock(&amp;ctx-&gt;mutex);</span><br><span class="line">	if (group_leader)</span><br><span class="line">		mutex_unlock(&amp;group_leader-&gt;group_leader_mutex);</span><br><span class="line"></span><br><span class="line">	if (task) &#123;</span><br><span class="line">		mutex_unlock(&amp;task-&gt;signal-&gt;cred_guard_mutex);</span><br><span class="line">		put_task_struct(task);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	put_online_cpus();</span><br><span class="line"></span><br><span class="line">	event-&gt;owner = current;</span><br><span class="line"></span><br><span class="line">    /* (9.2) 把当前进程创建的所有event，加入到current-&gt;perf_event_list链表中 */</span><br><span class="line">	mutex_lock(&amp;current-&gt;perf_event_mutex);</span><br><span class="line">	list_add_tail(&amp;event-&gt;owner_entry, &amp;current-&gt;perf_event_list);</span><br><span class="line">	mutex_unlock(&amp;current-&gt;perf_event_mutex);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Drop the reference on the group_event after placing the</span><br><span class="line">	 * new event on the sibling_list. This ensures destruction</span><br><span class="line">	 * of the group leader will find the pointer to itself in</span><br><span class="line">	 * perf_group_detach().</span><br><span class="line">	 */</span><br><span class="line">	fdput(group);</span><br><span class="line">	/* (9.3) 把fd和file进行链接 */</span><br><span class="line">	fd_install(event_fd, event_file);</span><br><span class="line">	return event_fd;</span><br><span class="line"></span><br><span class="line">err_locked:</span><br><span class="line">	if (move_group)</span><br><span class="line">		mutex_unlock(&amp;gctx-&gt;mutex);</span><br><span class="line">	mutex_unlock(&amp;ctx-&gt;mutex);</span><br><span class="line">/* err_file: */</span><br><span class="line">	fput(event_file);</span><br><span class="line">err_context:</span><br><span class="line">	perf_unpin_context(ctx);</span><br><span class="line">	put_ctx(ctx);</span><br><span class="line">err_alloc:</span><br><span class="line">	/*</span><br><span class="line">	 * If event_file is set, the fput() above will have called -&gt;release()</span><br><span class="line">	 * and that will take care of freeing the event.</span><br><span class="line">	 */</span><br><span class="line">	if (!event_file)</span><br><span class="line">		free_event(event);</span><br><span class="line">err_cred:</span><br><span class="line">	if (task)</span><br><span class="line">		mutex_unlock(&amp;task-&gt;signal-&gt;cred_guard_mutex);</span><br><span class="line">err_cpus:</span><br><span class="line">	put_online_cpus();</span><br><span class="line">err_task:</span><br><span class="line">	if (task)</span><br><span class="line">		put_task_struct(task);</span><br><span class="line">err_group_fd:</span><br><span class="line">	if (group_leader)</span><br><span class="line">		mutex_unlock(&amp;group_leader-&gt;group_leader_mutex);</span><br><span class="line">	fdput(group);</span><br><span class="line">err_fd:</span><br><span class="line">	put_unused_fd(event_fd);</span><br><span class="line">	return err;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|→</span><br><span class="line"></span><br><span class="line">static struct perf_event *</span><br><span class="line">perf_event_alloc(struct perf_event_attr *attr, int cpu,</span><br><span class="line">		 struct task_struct *task,</span><br><span class="line">		 struct perf_event *group_leader,</span><br><span class="line">		 struct perf_event *parent_event,</span><br><span class="line">		 perf_overflow_handler_t overflow_handler,</span><br><span class="line">		 void *context, int cgroup_fd)</span><br><span class="line">&#123;</span><br><span class="line">	struct pmu *pmu;</span><br><span class="line">	struct perf_event *event;</span><br><span class="line">	struct hw_perf_event *hwc;</span><br><span class="line">	long err = -EINVAL;</span><br><span class="line"></span><br><span class="line">	if ((unsigned)cpu &gt;= nr_cpu_ids) &#123;</span><br><span class="line">		if (!task || cpu != -1)</span><br><span class="line">			return ERR_PTR(-EINVAL);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.1) 分配perf_event空间 */</span><br><span class="line">	event = kzalloc(sizeof(*event), GFP_KERNEL);</span><br><span class="line">	if (!event)</span><br><span class="line">		return ERR_PTR(-ENOMEM);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Single events are their own group leaders, with an</span><br><span class="line">	 * empty sibling list:</span><br><span class="line">	 *</span><br><span class="line">	/* (2.2) 如果group_fd == -1，那么group_leader = self */</span><br><span class="line">	if (!group_leader)</span><br><span class="line">		group_leader = event;</span><br><span class="line"></span><br><span class="line">	mutex_init(&amp;event-&gt;group_leader_mutex);</span><br><span class="line">	mutex_init(&amp;event-&gt;child_mutex);</span><br><span class="line">	INIT_LIST_HEAD(&amp;event-&gt;child_list);</span><br><span class="line"></span><br><span class="line">	INIT_LIST_HEAD(&amp;event-&gt;group_entry);</span><br><span class="line">	INIT_LIST_HEAD(&amp;event-&gt;event_entry);</span><br><span class="line">	INIT_LIST_HEAD(&amp;event-&gt;sibling_list);</span><br><span class="line">	INIT_LIST_HEAD(&amp;event-&gt;rb_entry);</span><br><span class="line">	INIT_LIST_HEAD(&amp;event-&gt;active_entry);</span><br><span class="line">	INIT_LIST_HEAD(&amp;event-&gt;drv_configs);</span><br><span class="line">	INIT_HLIST_NODE(&amp;event-&gt;hlist_entry);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	init_waitqueue_head(&amp;event-&gt;waitq);</span><br><span class="line">	init_irq_work(&amp;event-&gt;pending, perf_pending_event);</span><br><span class="line"></span><br><span class="line">	mutex_init(&amp;event-&gt;mmap_mutex);</span><br><span class="line"></span><br><span class="line">	atomic_long_set(&amp;event-&gt;refcount, 1);</span><br><span class="line">	event-&gt;cpu		= cpu;</span><br><span class="line">	event-&gt;attr		= *attr;</span><br><span class="line">	event-&gt;group_leader	= group_leader;</span><br><span class="line">	event-&gt;pmu		= NULL;</span><br><span class="line">	event-&gt;oncpu		= -1;</span><br><span class="line"></span><br><span class="line">	event-&gt;parent		= parent_event;</span><br><span class="line"></span><br><span class="line">	event-&gt;ns		= get_pid_ns(task_active_pid_ns(current));</span><br><span class="line">	event-&gt;id		= atomic64_inc_return(&amp;perf_event_id);</span><br><span class="line"></span><br><span class="line">	event-&gt;state		= PERF_EVENT_STATE_INACTIVE;</span><br><span class="line"></span><br><span class="line">    /* (2.3) 如果task != null */</span><br><span class="line">	if (task) &#123;</span><br><span class="line">		event-&gt;attach_state = PERF_ATTACH_TASK;</span><br><span class="line">		/*</span><br><span class="line">		 * XXX pmu::event_init needs to know what task to account to</span><br><span class="line">		 * and we cannot use the ctx information because we need the</span><br><span class="line">		 * pmu before we get a ctx.</span><br><span class="line">		 */</span><br><span class="line">		event-&gt;hw.target = task;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	event-&gt;clock = &amp;local_clock;</span><br><span class="line">	if (parent_event)</span><br><span class="line">		event-&gt;clock = parent_event-&gt;clock;</span><br><span class="line"></span><br><span class="line">	if (!overflow_handler &amp;&amp; parent_event) &#123;</span><br><span class="line">		overflow_handler = parent_event-&gt;overflow_handler;</span><br><span class="line">		context = parent_event-&gt;overflow_handler_context;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	event-&gt;overflow_handler	= overflow_handler;</span><br><span class="line">	event-&gt;overflow_handler_context = context;</span><br><span class="line"></span><br><span class="line">    /* (2.4) 根据attr.disabled的值来设置event的初始化值：</span><br><span class="line">        event-&gt;state =  PERF_EVENT_STATE_OFF/PERF_EVENT_STATE_INACTIVE</span><br><span class="line">     */</span><br><span class="line">	perf_event__state_init(event);</span><br><span class="line"></span><br><span class="line">	pmu = NULL;</span><br><span class="line"></span><br><span class="line">    /* (2.5) 根据event的attr-&gt;freq和attr-&gt;sample_period/sample_freq来初始化event-&gt;hw:</span><br><span class="line">        hwc-&gt;sample_period</span><br><span class="line">        hwc-&gt;last_period</span><br><span class="line">        hwc-&gt;period_left</span><br><span class="line">     */</span><br><span class="line">	hwc = &amp;event-&gt;hw;</span><br><span class="line">	hwc-&gt;sample_period = attr-&gt;sample_period;</span><br><span class="line">	if (attr-&gt;freq &amp;&amp; attr-&gt;sample_freq)</span><br><span class="line">		hwc-&gt;sample_period = 1;</span><br><span class="line">	hwc-&gt;last_period = hwc-&gt;sample_period;</span><br><span class="line"></span><br><span class="line">	local64_set(&amp;hwc-&gt;period_left, hwc-&gt;sample_period);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * we currently do not support PERF_FORMAT_GROUP on inherited events</span><br><span class="line">	 */</span><br><span class="line">	/* (2.6) inherit时不支持PERF_FORMAT_GROUP */</span><br><span class="line">	if (attr-&gt;inherit &amp;&amp; (attr-&gt;read_format &amp; PERF_FORMAT_GROUP))</span><br><span class="line">		goto err_ns;</span><br><span class="line"></span><br><span class="line">    /* (2.7) 如果!(attr.sample_type &amp; PERF_SAMPLE_BRANCH_STACK)：</span><br><span class="line">        则attr.branch_sample_type = 0</span><br><span class="line">     */</span><br><span class="line">	if (!has_branch_stack(event))</span><br><span class="line">		event-&gt;attr.branch_sample_type = 0;</span><br><span class="line"></span><br><span class="line">    /* (2.8) 如果(flags &amp; PERF_FLAG_PID_CGROUP)：</span><br><span class="line">        将当前event加入cgroup </span><br><span class="line">     */</span><br><span class="line">	if (cgroup_fd != -1) &#123;</span><br><span class="line">		err = perf_cgroup_connect(cgroup_fd, event, attr, group_leader);</span><br><span class="line">		if (err)</span><br><span class="line">			goto err_ns;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.9) 至关重要的一步：</span><br><span class="line">        根据attr.type在pmus链表中找到对应的pmu，</span><br><span class="line">        并且调用pmu-&gt;event_init(event)来初始化event</span><br><span class="line">     */</span><br><span class="line">	pmu = perf_init_event(event);</span><br><span class="line">	if (!pmu)</span><br><span class="line">		goto err_ns;</span><br><span class="line">	else if (IS_ERR(pmu)) &#123;</span><br><span class="line">		err = PTR_ERR(pmu);</span><br><span class="line">		goto err_ns;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.10) exclusive类型pmu的event的处理 */</span><br><span class="line">	err = exclusive_event_init(event);</span><br><span class="line">	if (err)</span><br><span class="line">		goto err_pmu;</span><br><span class="line"></span><br><span class="line">	if (!event-&gt;parent) &#123;</span><br><span class="line">		if (event-&gt;attr.sample_type &amp; PERF_SAMPLE_CALLCHAIN) &#123;</span><br><span class="line">			err = get_callchain_buffers();</span><br><span class="line">			if (err)</span><br><span class="line">				goto err_per_task;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/* symmetric to unaccount_event() in _free_event() */</span><br><span class="line">	/* (2.11) 关于event操作的一些统计 */</span><br><span class="line">	account_event(event);</span><br><span class="line"></span><br><span class="line">	return event;</span><br><span class="line"></span><br><span class="line">err_per_task:</span><br><span class="line">	exclusive_event_destroy(event);</span><br><span class="line"></span><br><span class="line">err_pmu:</span><br><span class="line">	if (event-&gt;destroy)</span><br><span class="line">		event-&gt;destroy(event);</span><br><span class="line">	module_put(pmu-&gt;module);</span><br><span class="line">err_ns:</span><br><span class="line">	if (is_cgroup_event(event))</span><br><span class="line">		perf_detach_cgroup(event);</span><br><span class="line">	if (event-&gt;ns)</span><br><span class="line">		put_pid_ns(event-&gt;ns);</span><br><span class="line">	kfree(event);</span><br><span class="line"></span><br><span class="line">	return ERR_PTR(err);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|→</span><br><span class="line"></span><br><span class="line">static struct perf_event_context *</span><br><span class="line">find_get_context(struct pmu *pmu, struct task_struct *task,</span><br><span class="line">		struct perf_event *event)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event_context *ctx, *clone_ctx = NULL;</span><br><span class="line">	struct perf_cpu_context *cpuctx;</span><br><span class="line">	void *task_ctx_data = NULL;</span><br><span class="line">	unsigned long flags;</span><br><span class="line">	int ctxn, err;</span><br><span class="line">	int cpu = event-&gt;cpu;</span><br><span class="line"></span><br><span class="line">    /* (4.1) 如果task=null即pid=-1，获取cpu维度的context */</span><br><span class="line">	if (!task) &#123;</span><br><span class="line">		/* Must be root to operate on a CPU event: */</span><br><span class="line">		/* (4.1.1) 权限判断 */</span><br><span class="line">		if (event-&gt;owner != EVENT_OWNER_KERNEL &amp;&amp; perf_paranoid_cpu() &amp;&amp;</span><br><span class="line">			!capable(CAP_SYS_ADMIN))</span><br><span class="line">			return ERR_PTR(-EACCES);</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * We could be clever and allow to attach a event to an</span><br><span class="line">		 * offline CPU and activate it when the CPU comes up, but</span><br><span class="line">		 * that&apos;s for later.</span><br><span class="line">		 */</span><br><span class="line">		/* (4.1.2) attr指定的cpu是否online */</span><br><span class="line">		if (!cpu_online(cpu))</span><br><span class="line">			return ERR_PTR(-ENODEV);</span><br><span class="line"></span><br><span class="line">        /* (4.1.3) 根据cpu获取到对应pmu的cpu维度context：per_cpu_ptr(pmu-&gt;pmu_cpu_context, cpu)-&gt;ctx */</span><br><span class="line">		cpuctx = per_cpu_ptr(pmu-&gt;pmu_cpu_context, cpu);</span><br><span class="line">		ctx = &amp;cpuctx-&gt;ctx;</span><br><span class="line">		get_ctx(ctx);</span><br><span class="line">		++ctx-&gt;pin_count;</span><br><span class="line"></span><br><span class="line">		return ctx;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/* (4.2) 如果task!=null即pid&gt;=0，获取task维度的context */</span><br><span class="line"></span><br><span class="line">	err = -EINVAL;</span><br><span class="line">	ctxn = pmu-&gt;task_ctx_nr;</span><br><span class="line">	if (ctxn &lt; 0)</span><br><span class="line">		goto errout;</span><br><span class="line"></span><br><span class="line">    /* (4.2.1) 部分架构context需要分配ctx-&gt;task_ctx_data */</span><br><span class="line">	if (event-&gt;attach_state &amp; PERF_ATTACH_TASK_DATA) &#123;</span><br><span class="line">		task_ctx_data = kzalloc(pmu-&gt;task_ctx_size, GFP_KERNEL);</span><br><span class="line">		if (!task_ctx_data) &#123;</span><br><span class="line">			err = -ENOMEM;</span><br><span class="line">			goto errout;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">retry:</span><br><span class="line">    /* (4.2.2) 获取task维度的context：task-&gt;perf_event_ctxp[pmu-&gt;task_ctx_nr]</span><br><span class="line">        如果此前无人创建过此context，则分配空间创建</span><br><span class="line">     */</span><br><span class="line">	ctx = perf_lock_task_context(task, ctxn, &amp;flags);</span><br><span class="line">	/* (4.2.2.1) task此context已经创建，则使用现成的 */</span><br><span class="line">	if (ctx) &#123;</span><br><span class="line">		clone_ctx = unclone_ctx(ctx);</span><br><span class="line">		++ctx-&gt;pin_count;</span><br><span class="line"></span><br><span class="line">		if (task_ctx_data &amp;&amp; !ctx-&gt;task_ctx_data) &#123;</span><br><span class="line">			ctx-&gt;task_ctx_data = task_ctx_data;</span><br><span class="line">			task_ctx_data = NULL;</span><br><span class="line">		&#125;</span><br><span class="line">		raw_spin_unlock_irqrestore(&amp;ctx-&gt;lock, flags);</span><br><span class="line"></span><br><span class="line">		if (clone_ctx)</span><br><span class="line">			put_ctx(clone_ctx);</span><br><span class="line">	/* (4.2.2.2) 否则，重新创建task-&gt;perf_event_ctxp[pmu-&gt;task_ctx_nr] */</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		ctx = alloc_perf_context(pmu, task);</span><br><span class="line">		err = -ENOMEM;</span><br><span class="line">		if (!ctx)</span><br><span class="line">			goto errout;</span><br><span class="line"></span><br><span class="line">		if (task_ctx_data) &#123;</span><br><span class="line">			ctx-&gt;task_ctx_data = task_ctx_data;</span><br><span class="line">			task_ctx_data = NULL;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		err = 0;</span><br><span class="line">		mutex_lock(&amp;task-&gt;perf_event_mutex);</span><br><span class="line">		/*</span><br><span class="line">		 * If it has already passed perf_event_exit_task().</span><br><span class="line">		 * we must see PF_EXITING, it takes this mutex too.</span><br><span class="line">		 */</span><br><span class="line">		if (task-&gt;flags &amp; PF_EXITING)</span><br><span class="line">			err = -ESRCH;</span><br><span class="line">		else if (task-&gt;perf_event_ctxp[ctxn])</span><br><span class="line">			err = -EAGAIN;</span><br><span class="line">		else &#123;</span><br><span class="line">			get_ctx(ctx);</span><br><span class="line">			++ctx-&gt;pin_count;</span><br><span class="line">			rcu_assign_pointer(task-&gt;perf_event_ctxp[ctxn], ctx);</span><br><span class="line">		&#125;</span><br><span class="line">		mutex_unlock(&amp;task-&gt;perf_event_mutex);</span><br><span class="line"></span><br><span class="line">		if (unlikely(err)) &#123;</span><br><span class="line">			put_ctx(ctx);</span><br><span class="line"></span><br><span class="line">			if (err == -EAGAIN)</span><br><span class="line">				goto retry;</span><br><span class="line">			goto errout;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	kfree(task_ctx_data);</span><br><span class="line">	return ctx;</span><br><span class="line"></span><br><span class="line">errout:</span><br><span class="line">	kfree(task_ctx_data);</span><br><span class="line">	return ERR_PTR(err);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|→</span><br><span class="line"></span><br><span class="line">static void</span><br><span class="line">perf_install_in_context(struct perf_event_context *ctx,</span><br><span class="line">			struct perf_event *event,</span><br><span class="line">			int cpu)</span><br><span class="line">&#123;</span><br><span class="line">	struct task_struct *task = ctx-&gt;task;</span><br><span class="line"></span><br><span class="line">	lockdep_assert_held(&amp;ctx-&gt;mutex);</span><br><span class="line"></span><br><span class="line">    /* (10.1) context赋值给event-&gt;ctx */</span><br><span class="line">	event-&gt;ctx = ctx;</span><br><span class="line">	if (event-&gt;cpu != -1)</span><br><span class="line">		event-&gt;cpu = cpu;</span><br><span class="line"></span><br><span class="line">    /* (10.2) 如果是cpu维度的context，</span><br><span class="line">        使用cpu同步机制来调用指定的cpu上运行__perf_install_in_context() </span><br><span class="line">        绑定context、event</span><br><span class="line">     */</span><br><span class="line">	if (!task) &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * Per cpu events are installed via an smp call and</span><br><span class="line">		 * the install is always successful.</span><br><span class="line">		 */</span><br><span class="line">		cpu_function_call(cpu, __perf_install_in_context, event);</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">retry:</span><br><span class="line">    /* (10.3) 如果是task维度的context，且task当前正在running</span><br><span class="line">        使用cpu同步机制调用指定的task的运行cpu(即task_cpu(p))上运行__perf_install_in_context()</span><br><span class="line">        绑定context、event</span><br><span class="line">     */</span><br><span class="line">	if (!task_function_call(task, __perf_install_in_context, event))</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	raw_spin_lock_irq(&amp;ctx-&gt;lock);</span><br><span class="line">	/*</span><br><span class="line">	 * If we failed to find a running task, but find the context active now</span><br><span class="line">	 * that we&apos;ve acquired the ctx-&gt;lock, retry.</span><br><span class="line">	 */</span><br><span class="line">	if (ctx-&gt;is_active) &#123;</span><br><span class="line">		raw_spin_unlock_irq(&amp;ctx-&gt;lock);</span><br><span class="line">		/*</span><br><span class="line">		 * Reload the task pointer, it might have been changed by</span><br><span class="line">		 * a concurrent perf_event_context_sched_out().</span><br><span class="line">		 */</span><br><span class="line">		task = ctx-&gt;task;</span><br><span class="line">		goto retry;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Since the task isn&apos;t running, its safe to add the event, us holding</span><br><span class="line">	 * the ctx-&gt;lock ensures the task won&apos;t get scheduled in.</span><br><span class="line">	 */</span><br><span class="line">	/* (10.4) 如果是task维度的context，但是task当前不在runnning</span><br><span class="line">        可以安全的绑定event和context</span><br><span class="line">     */</span><br><span class="line">	add_event_to_ctx(event, ctx);</span><br><span class="line">	raw_spin_unlock_irq(&amp;ctx-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||→</span><br><span class="line"></span><br><span class="line">static void add_event_to_ctx(struct perf_event *event,</span><br><span class="line">			       struct perf_event_context *ctx)</span><br><span class="line">&#123;</span><br><span class="line">	u64 tstamp = perf_event_time(event);</span><br><span class="line"></span><br><span class="line">    /* (10.4.1) 将event加入到context的相关链表 */</span><br><span class="line">	list_add_event(event, ctx);</span><br><span class="line">	</span><br><span class="line">	/* (10.4.2) 将event加入到group_leader的链表 */</span><br><span class="line">	perf_group_attach(event);</span><br><span class="line">	event-&gt;tstamp_enabled = tstamp;</span><br><span class="line">	event-&gt;tstamp_running = tstamp;</span><br><span class="line">	event-&gt;tstamp_stopped = tstamp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||→</span><br><span class="line"></span><br><span class="line">static void</span><br><span class="line">list_add_event(struct perf_event *event, struct perf_event_context *ctx)</span><br><span class="line">&#123;</span><br><span class="line">	WARN_ON_ONCE(event-&gt;attach_state &amp; PERF_ATTACH_CONTEXT);</span><br><span class="line">	</span><br><span class="line">	/* (10.4.1.1) 设置event-&gt;attach_state的PERF_ATTACH_CONTEXT */</span><br><span class="line">	event-&gt;attach_state |= PERF_ATTACH_CONTEXT;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * If we&apos;re a stand alone event or group leader, we go to the context</span><br><span class="line">	 * list, group events are kept attached to the group so that</span><br><span class="line">	 * perf_group_detach can, at all times, locate all siblings.</span><br><span class="line">	 */</span><br><span class="line">	/* (10.4.1.2) 如果event是group_leader </span><br><span class="line">	    则将其event-&gt;group_entry加入到顶级group链表：ctx-&gt;flexible_groups/pinned_groups</span><br><span class="line">	    ctx-&gt;flexible_groups/pinned_groups链表只链接group_leader的event</span><br><span class="line">	 */</span><br><span class="line">	if (event-&gt;group_leader == event) &#123;</span><br><span class="line">		struct list_head *list;</span><br><span class="line"></span><br><span class="line">		if (is_software_event(event))</span><br><span class="line">			event-&gt;group_flags |= PERF_GROUP_SOFTWARE;</span><br><span class="line"></span><br><span class="line">		list = ctx_group_list(event, ctx);</span><br><span class="line">		list_add_tail(&amp;event-&gt;group_entry, list);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (is_cgroup_event(event))</span><br><span class="line">		ctx-&gt;nr_cgroups++;</span><br><span class="line"></span><br><span class="line">    /* (10.4.1.3) 将event-&gt;event_entry加入到链表：ctx-&gt;event_list </span><br><span class="line">        ctx-&gt;event_list链表链接context下所有的event</span><br><span class="line">     */</span><br><span class="line">	list_add_rcu(&amp;event-&gt;event_entry, &amp;ctx-&gt;event_list);</span><br><span class="line">	ctx-&gt;nr_events++;</span><br><span class="line">	if (event-&gt;attr.inherit_stat)</span><br><span class="line">		ctx-&gt;nr_stat++;</span><br><span class="line"></span><br><span class="line">	ctx-&gt;generation++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||→</span><br><span class="line"></span><br><span class="line">static void perf_group_attach(struct perf_event *event)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *group_leader = event-&gt;group_leader, *pos;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We can have double attach due to group movement in perf_event_open.</span><br><span class="line">	 */</span><br><span class="line">	/* (10.4.2.1) 设置event-&gt;attach_state的PERF_ATTACH_GROUP */</span><br><span class="line">	if (event-&gt;attach_state &amp; PERF_ATTACH_GROUP)</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	event-&gt;attach_state |= PERF_ATTACH_GROUP;</span><br><span class="line"></span><br><span class="line">    /* (10.4.2.2) 如果event本身就是group_leader，不需要继续操作 */</span><br><span class="line">	if (group_leader == event)</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	WARN_ON_ONCE(group_leader-&gt;ctx != event-&gt;ctx);</span><br><span class="line"></span><br><span class="line">    /* (10.4.2.3) move_group的处理？ */</span><br><span class="line">	if (group_leader-&gt;group_flags &amp; PERF_GROUP_SOFTWARE &amp;&amp;</span><br><span class="line">			!is_software_event(event))</span><br><span class="line">		group_leader-&gt;group_flags &amp;= ~PERF_GROUP_SOFTWARE;</span><br><span class="line"></span><br><span class="line">    /* (10.4.2.4) 把event-&gt;group_entry加入到group_leader-&gt;sibling_list链表 */</span><br><span class="line">	list_add_tail(&amp;event-&gt;group_entry, &amp;group_leader-&gt;sibling_list);</span><br><span class="line">	group_leader-&gt;nr_siblings++;</span><br><span class="line"></span><br><span class="line">    /* (10.4.2.5) 重新计算group_leader的event-&gt;read_size、event-&gt;header_size */</span><br><span class="line">	perf_event__header_size(group_leader);</span><br><span class="line"></span><br><span class="line">    /* (10.4.2.6) 重新计算group_leader所有子event的event-&gt;read_size、event-&gt;header_size */</span><br><span class="line">	list_for_each_entry(pos, &amp;group_leader-&gt;sibling_list, group_entry)</span><br><span class="line">		perf_event__header_size(pos);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>经过perf_event_open()调用以后返回perf_event对应的fd，后续的文件操作对应perf_fops：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">static const struct file_operations perf_fops = &#123;</span><br><span class="line">	.llseek			= no_llseek,</span><br><span class="line">	.release		= perf_release,</span><br><span class="line">	.read			= perf_read,</span><br><span class="line">	.poll			= perf_poll,</span><br><span class="line">	.unlocked_ioctl		= perf_ioctl,</span><br><span class="line">	.compat_ioctl		= perf_compat_ioctl,</span><br><span class="line">	.mmap			= perf_mmap,</span><br><span class="line">	.fasync			= perf_fasync,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>后续会对其重点的函数perf_read()、perf_ioctl()、perf_mmap()一一进行解析。</p>
<h2 id="2-1、inherit"><a href="#2-1、inherit" class="headerlink" title="2.1、inherit"></a>2.1、inherit</h2><p>进程通过task contex(task-&gt;perf_event_ctxp[ctxn])挂载了很多面向task的perf_event，如果event支持inherit属性，当进程创建子进程时需要给子进程创建task context和继承的event。</p>
<p>copy_process() -&gt; perf_event_init_task() -&gt; perf_event_init_context() -&gt; inherit_task_group() -&gt; inherit_group() -&gt; inherit_event():</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br></pre></td><td class="code"><pre><span class="line">int perf_event_init_task(struct task_struct *child)</span><br><span class="line">&#123;</span><br><span class="line">	int ctxn, ret;</span><br><span class="line"></span><br><span class="line">    /* (1) 初始化child task的perf_event相关结构 */</span><br><span class="line">	memset(child-&gt;perf_event_ctxp, 0, sizeof(child-&gt;perf_event_ctxp));</span><br><span class="line">	mutex_init(&amp;child-&gt;perf_event_mutex);</span><br><span class="line">	INIT_LIST_HEAD(&amp;child-&gt;perf_event_list);</span><br><span class="line"></span><br><span class="line">    /* (2) 进程通过task contex(task-&gt;perf_event_ctxp[ctxn])挂载了很多面向task的perf_event，</span><br><span class="line">        如果event支持inherit属性，当进程创建子进程时需要给子进程创建task context和继承的event</span><br><span class="line">     */</span><br><span class="line">	for_each_task_context_nr(ctxn) &#123;</span><br><span class="line">		ret = perf_event_init_context(child, ctxn);</span><br><span class="line">		if (ret) &#123;</span><br><span class="line">			perf_event_free_task(child);</span><br><span class="line">			return ret;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|→</span><br><span class="line"></span><br><span class="line">static int perf_event_init_context(struct task_struct *child, int ctxn)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event_context *child_ctx, *parent_ctx;</span><br><span class="line">	struct perf_event_context *cloned_ctx;</span><br><span class="line">	struct perf_event *event;</span><br><span class="line">	struct task_struct *parent = current;</span><br><span class="line">	int inherited_all = 1;</span><br><span class="line">	unsigned long flags;</span><br><span class="line">	int ret = 0;</span><br><span class="line"></span><br><span class="line">    /* (2.1) 父进程即为当前进程(current) */</span><br><span class="line">	if (likely(!parent-&gt;perf_event_ctxp[ctxn]))</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * If the parent&apos;s context is a clone, pin it so it won&apos;t get</span><br><span class="line">	 * swapped under us.</span><br><span class="line">	 */</span><br><span class="line">	parent_ctx = perf_pin_task_context(parent, ctxn);</span><br><span class="line">	if (!parent_ctx)</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * No need to check if parent_ctx != NULL here; since we saw</span><br><span class="line">	 * it non-NULL earlier, the only reason for it to become NULL</span><br><span class="line">	 * is if we exit, and since we&apos;re currently in the middle of</span><br><span class="line">	 * a fork we can&apos;t be exiting at the same time.</span><br><span class="line">	 */</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Lock the parent list. No need to lock the child - not PID</span><br><span class="line">	 * hashed yet and not running, so nobody can access it.</span><br><span class="line">	 */</span><br><span class="line">	mutex_lock(&amp;parent_ctx-&gt;mutex);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We dont have to disable NMIs - we are only looking at</span><br><span class="line">	 * the list, not manipulating it:</span><br><span class="line">	 */</span><br><span class="line">	/* (2.2) 遍历父进程context上的高优先级group leader event链表：parent_ctx-&gt;pinned_groups，</span><br><span class="line">	    在子进程上复制需要inherit的event</span><br><span class="line">	 */</span><br><span class="line">	list_for_each_entry(event, &amp;parent_ctx-&gt;pinned_groups, group_entry) &#123;</span><br><span class="line">		ret = inherit_task_group(event, parent, parent_ctx,</span><br><span class="line">					 child, ctxn, &amp;inherited_all);</span><br><span class="line">		if (ret)</span><br><span class="line">			break;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We can&apos;t hold ctx-&gt;lock when iterating the -&gt;flexible_group list due</span><br><span class="line">	 * to allocations, but we need to prevent rotation because</span><br><span class="line">	 * rotate_ctx() will change the list from interrupt context.</span><br><span class="line">	 */</span><br><span class="line">	raw_spin_lock_irqsave(&amp;parent_ctx-&gt;lock, flags);</span><br><span class="line">	parent_ctx-&gt;rotate_disable = 1;</span><br><span class="line">	raw_spin_unlock_irqrestore(&amp;parent_ctx-&gt;lock, flags);</span><br><span class="line"></span><br><span class="line">    /* (2.2) 遍历父进程context上的低优先级group leader event链表：parent_ctx-&gt;flexible_groups，</span><br><span class="line">	    在子进程上复制需要inherit的event</span><br><span class="line">	 */</span><br><span class="line">	list_for_each_entry(event, &amp;parent_ctx-&gt;flexible_groups, group_entry) &#123;</span><br><span class="line">		ret = inherit_task_group(event, parent, parent_ctx,</span><br><span class="line">					 child, ctxn, &amp;inherited_all);</span><br><span class="line">		if (ret)</span><br><span class="line">			break;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	raw_spin_lock_irqsave(&amp;parent_ctx-&gt;lock, flags);</span><br><span class="line">	parent_ctx-&gt;rotate_disable = 0;</span><br><span class="line"></span><br><span class="line">	child_ctx = child-&gt;perf_event_ctxp[ctxn];</span><br><span class="line"></span><br><span class="line">    /* (2.3) 如果inherited_all&gt;0，表示父进程挂载的所有event都是inherit属性，都被子进程复制继承， </span><br><span class="line">        那么给子进程的task context-&gt;parent_ctx赋值为父进程的context</span><br><span class="line">     */</span><br><span class="line">	if (child_ctx &amp;&amp; inherited_all) &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * Mark the child context as a clone of the parent</span><br><span class="line">		 * context, or of whatever the parent is a clone of.</span><br><span class="line">		 *</span><br><span class="line">		 * Note that if the parent is a clone, the holding of</span><br><span class="line">		 * parent_ctx-&gt;lock avoids it from being uncloned.</span><br><span class="line">		 */</span><br><span class="line">		cloned_ctx = parent_ctx-&gt;parent_ctx;</span><br><span class="line">		if (cloned_ctx) &#123;</span><br><span class="line">			child_ctx-&gt;parent_ctx = cloned_ctx;</span><br><span class="line">			child_ctx-&gt;parent_gen = parent_ctx-&gt;parent_gen;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			child_ctx-&gt;parent_ctx = parent_ctx;</span><br><span class="line">			child_ctx-&gt;parent_gen = parent_ctx-&gt;generation;</span><br><span class="line">		&#125;</span><br><span class="line">		get_ctx(child_ctx-&gt;parent_ctx);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	raw_spin_unlock_irqrestore(&amp;parent_ctx-&gt;lock, flags);</span><br><span class="line">	mutex_unlock(&amp;parent_ctx-&gt;mutex);</span><br><span class="line"></span><br><span class="line">	perf_unpin_context(parent_ctx);</span><br><span class="line">	put_ctx(parent_ctx);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||→</span><br><span class="line"></span><br><span class="line">static int</span><br><span class="line">inherit_task_group(struct perf_event *event, struct task_struct *parent,</span><br><span class="line">		   struct perf_event_context *parent_ctx,</span><br><span class="line">		   struct task_struct *child, int ctxn,</span><br><span class="line">		   int *inherited_all)</span><br><span class="line">&#123;</span><br><span class="line">	int ret;</span><br><span class="line">	struct perf_event_context *child_ctx;</span><br><span class="line"></span><br><span class="line">    /* (2.1.1) 如果event不支持inherit，直接返回 */</span><br><span class="line">	if (!event-&gt;attr.inherit) &#123;</span><br><span class="line">		*inherited_all = 0;</span><br><span class="line">		return 0;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.1.2) 如果子进程的context为空，分配创建 */</span><br><span class="line">	child_ctx = child-&gt;perf_event_ctxp[ctxn];</span><br><span class="line">	if (!child_ctx) &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * This is executed from the parent task context, so</span><br><span class="line">		 * inherit events that have been marked for cloning.</span><br><span class="line">		 * First allocate and initialize a context for the</span><br><span class="line">		 * child.</span><br><span class="line">		 */</span><br><span class="line"></span><br><span class="line">		child_ctx = alloc_perf_context(parent_ctx-&gt;pmu, child);</span><br><span class="line">		if (!child_ctx)</span><br><span class="line">			return -ENOMEM;</span><br><span class="line"></span><br><span class="line">		child-&gt;perf_event_ctxp[ctxn] = child_ctx;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.1.3) 子进程对父进程的event进行复制继承 */</span><br><span class="line">	ret = inherit_group(event, parent, parent_ctx,</span><br><span class="line">			    child, child_ctx);</span><br><span class="line"></span><br><span class="line">	if (ret)</span><br><span class="line">		*inherited_all = 0;</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||→</span><br><span class="line"></span><br><span class="line">static int inherit_group(struct perf_event *parent_event,</span><br><span class="line">	      struct task_struct *parent,</span><br><span class="line">	      struct perf_event_context *parent_ctx,</span><br><span class="line">	      struct task_struct *child,</span><br><span class="line">	      struct perf_event_context *child_ctx)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *leader;</span><br><span class="line">	struct perf_event *sub;</span><br><span class="line">	struct perf_event *child_ctr;</span><br><span class="line"></span><br><span class="line">    /* (2.1.3.1) 对group_leader event进行复制继承， </span><br><span class="line">        新建group leader的继承者是新的group leader</span><br><span class="line">     */</span><br><span class="line">	leader = inherit_event(parent_event, parent, parent_ctx,</span><br><span class="line">				 child, NULL, child_ctx);</span><br><span class="line">	if (IS_ERR(leader))</span><br><span class="line">		return PTR_ERR(leader);</span><br><span class="line">		</span><br><span class="line">	/* (2.1.3.2) 对group_leader下面的子event进行复制继承： </span><br><span class="line">	    如果父进程group leader下面有树成员，他会把这棵树给子进程也复制一份，</span><br><span class="line">	    ---oops：这里有个疑问，如果父进程group成员不是group leader所在的父进程，但是inherit会给子进程复制一个event，这样合理吗？</span><br><span class="line">	 */</span><br><span class="line">	list_for_each_entry(sub, &amp;parent_event-&gt;sibling_list, group_entry) &#123;</span><br><span class="line">		child_ctr = inherit_event(sub, parent, parent_ctx,</span><br><span class="line">					    child, leader, child_ctx);</span><br><span class="line">		if (IS_ERR(child_ctr))</span><br><span class="line">			return PTR_ERR(child_ctr);</span><br><span class="line">	&#125;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||||→</span><br><span class="line"></span><br><span class="line">static struct perf_event *</span><br><span class="line">inherit_event(struct perf_event *parent_event,</span><br><span class="line">	      struct task_struct *parent,</span><br><span class="line">	      struct perf_event_context *parent_ctx,</span><br><span class="line">	      struct task_struct *child,</span><br><span class="line">	      struct perf_event *group_leader,</span><br><span class="line">	      struct perf_event_context *child_ctx)</span><br><span class="line">&#123;</span><br><span class="line">	enum perf_event_active_state parent_state = parent_event-&gt;state;</span><br><span class="line">	struct perf_event *child_event;</span><br><span class="line">	unsigned long flags;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Instead of creating recursive hierarchies of events,</span><br><span class="line">	 * we link inherited events back to the original parent,</span><br><span class="line">	 * which has a filp for sure, which we use as the reference</span><br><span class="line">	 * count:</span><br><span class="line">	 */</span><br><span class="line">	/* (2.1.3.1.1) 获得子进程新建event的parent event，</span><br><span class="line">	    如果是多级子进程，把所有子进程的event都挂在原始parent下面，而不是一级一级的挂载</span><br><span class="line">	 */</span><br><span class="line">	if (parent_event-&gt;parent)</span><br><span class="line">		parent_event = parent_event-&gt;parent;</span><br><span class="line"></span><br><span class="line">    /* (2.1.3.2) 对group_leader event进行复制，重新分配初始化： </span><br><span class="line">        和父event创建不同，这指定了子event的parent：event-&gt;parent = parent_event;</span><br><span class="line">        随后子event也会被加入到父event的parent_event-&gt;child_list链表中</span><br><span class="line">     */</span><br><span class="line">	child_event = perf_event_alloc(&amp;parent_event-&gt;attr,</span><br><span class="line">					   parent_event-&gt;cpu,</span><br><span class="line">					   child,</span><br><span class="line">					   group_leader, parent_event,</span><br><span class="line">					   NULL, NULL, -1);</span><br><span class="line">	if (IS_ERR(child_event))</span><br><span class="line">		return child_event;</span><br><span class="line"></span><br><span class="line">	if (is_orphaned_event(parent_event) ||</span><br><span class="line">	    !atomic_long_inc_not_zero(&amp;parent_event-&gt;refcount)) &#123;</span><br><span class="line">		free_event(child_event);</span><br><span class="line">		return NULL;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	get_ctx(child_ctx);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Make the child state follow the state of the parent event,</span><br><span class="line">	 * not its attr.disabled bit.  We hold the parent&apos;s mutex,</span><br><span class="line">	 * so we won&apos;t race with perf_event_&#123;en, dis&#125;able_family.</span><br><span class="line">	 */</span><br><span class="line">	/* (2.1.3.3) 如果父event的状态已经enable，子event的状态也为enable */</span><br><span class="line">	if (parent_state &gt;= PERF_EVENT_STATE_INACTIVE)</span><br><span class="line">		child_event-&gt;state = PERF_EVENT_STATE_INACTIVE;</span><br><span class="line">	else</span><br><span class="line">		child_event-&gt;state = PERF_EVENT_STATE_OFF;</span><br><span class="line"></span><br><span class="line">	if (parent_event-&gt;attr.freq) &#123;</span><br><span class="line">		u64 sample_period = parent_event-&gt;hw.sample_period;</span><br><span class="line">		struct hw_perf_event *hwc = &amp;child_event-&gt;hw;</span><br><span class="line"></span><br><span class="line">		hwc-&gt;sample_period = sample_period;</span><br><span class="line">		hwc-&gt;last_period   = sample_period;</span><br><span class="line"></span><br><span class="line">		local64_set(&amp;hwc-&gt;period_left, sample_period);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	child_event-&gt;ctx = child_ctx;</span><br><span class="line">	child_event-&gt;overflow_handler = parent_event-&gt;overflow_handler;</span><br><span class="line">	child_event-&gt;overflow_handler_context</span><br><span class="line">		= parent_event-&gt;overflow_handler_context;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Precalculate sample_data sizes</span><br><span class="line">	 */</span><br><span class="line">	perf_event__header_size(child_event);</span><br><span class="line">	perf_event__id_header_size(child_event);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Link it up in the child&apos;s context:</span><br><span class="line">	 */</span><br><span class="line">	/* (2.1.3.4) 将新的event加入到子进程的context中 */</span><br><span class="line">	raw_spin_lock_irqsave(&amp;child_ctx-&gt;lock, flags);</span><br><span class="line">	add_event_to_ctx(child_event, child_ctx);</span><br><span class="line">	raw_spin_unlock_irqrestore(&amp;child_ctx-&gt;lock, flags);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Link this into the parent event&apos;s child list</span><br><span class="line">	 */</span><br><span class="line">	/* (2.1.3.5) 将子event加入到父event的-&gt;child_list链表中 */</span><br><span class="line">	WARN_ON_ONCE(parent_event-&gt;ctx-&gt;parent_ctx);</span><br><span class="line">	mutex_lock(&amp;parent_event-&gt;child_mutex);</span><br><span class="line">	list_add_tail(&amp;child_event-&gt;child_list, &amp;parent_event-&gt;child_list);</span><br><span class="line">	mutex_unlock(&amp;parent_event-&gt;child_mutex);</span><br><span class="line"></span><br><span class="line">	return child_event;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-2、perf-task-sched"><a href="#2-2、perf-task-sched" class="headerlink" title="2.2、perf task sched"></a>2.2、perf task sched</h2><p>task context上链接的perf_event需要跟随task进程调度一起动态启动停止，在task得到调度时相关perf_event开始工作，在task被其他任务调度出去时相关perf_event停止工作。</p>
<p>为了支持这种行为，在task switch时调用perf的回调函数：perf_event_task_sched_out()/perf_event_task_sched_in()</p>
<p>context_switch() -&gt; prepare_task_switch() -&gt; perf_event_task_sched_out():</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br></pre></td><td class="code"><pre><span class="line">static inline void perf_event_task_sched_out(struct task_struct *prev,</span><br><span class="line">					     struct task_struct *next)</span><br><span class="line">&#123;</span><br><span class="line">    /* (1) &quot;software&quot; pmu 子类型为“context-switches”的数据采集点 */</span><br><span class="line">	perf_sw_event_sched(PERF_COUNT_SW_CONTEXT_SWITCHES, 1, 0);</span><br><span class="line"></span><br><span class="line">    /* (2) 随着taskswitch，和task关联的相关event需要停止工作：即sched_out </span><br><span class="line">        perf_sched_events.key：是进行perf_sched_in/out的开关，在event分配(perf_event_alloc() -&gt; account_event())和释放(_free_event() -&gt; unaccount_event())时操作</span><br><span class="line">     */</span><br><span class="line">	if (static_key_false(&amp;perf_sched_events.key))</span><br><span class="line">		__perf_event_task_sched_out(prev, next);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|→</span><br><span class="line"></span><br><span class="line">void __perf_event_task_sched_out(struct task_struct *task,</span><br><span class="line">				 struct task_struct *next)</span><br><span class="line">&#123;</span><br><span class="line">	int ctxn;</span><br><span class="line"></span><br><span class="line">    /* (2.1) 回调函数pmu-&gt;sched_task的调用点 */</span><br><span class="line">	if (__this_cpu_read(perf_sched_cb_usages))</span><br><span class="line">		perf_pmu_sched_task(task, next, false);</span><br><span class="line"></span><br><span class="line">    /* (2.2) */</span><br><span class="line">	if (atomic_read(&amp;nr_switch_events))</span><br><span class="line">		perf_event_switch(task, next, false);</span><br><span class="line"></span><br><span class="line">    /* (2.3) 遍历task-&gt;[perf_event_ctxp]中的context， </span><br><span class="line">        逐个关闭context链接中的每个perf_event</span><br><span class="line">     */</span><br><span class="line">	for_each_task_context_nr(ctxn)</span><br><span class="line">		perf_event_context_sched_out(task, ctxn, next);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * if cgroup events exist on this CPU, then we need</span><br><span class="line">	 * to check if we have to switch out PMU state.</span><br><span class="line">	 * cgroup event are system-wide mode only</span><br><span class="line">	 */</span><br><span class="line">	/* (2.4) task cgroup相关sched_out */</span><br><span class="line">	if (atomic_read(this_cpu_ptr(&amp;perf_cgroup_events)))</span><br><span class="line">		perf_cgroup_sched_out(task, next);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||→</span><br><span class="line"></span><br><span class="line">static void perf_event_context_sched_out(struct task_struct *task, int ctxn,</span><br><span class="line">					 struct task_struct *next)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event_context *ctx = task-&gt;perf_event_ctxp[ctxn];</span><br><span class="line">	struct perf_event_context *next_ctx;</span><br><span class="line">	struct perf_event_context *parent, *next_parent;</span><br><span class="line">	struct perf_cpu_context *cpuctx;</span><br><span class="line">	int do_switch = 1;</span><br><span class="line"></span><br><span class="line">	if (likely(!ctx))</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	cpuctx = __get_cpu_context(ctx);</span><br><span class="line">	if (!cpuctx-&gt;task_ctx)</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	rcu_read_lock();</span><br><span class="line">	next_ctx = next-&gt;perf_event_ctxp[ctxn];</span><br><span class="line">	if (!next_ctx)</span><br><span class="line">		goto unlock;</span><br><span class="line"></span><br><span class="line">	parent = rcu_dereference(ctx-&gt;parent_ctx);</span><br><span class="line">	next_parent = rcu_dereference(next_ctx-&gt;parent_ctx);</span><br><span class="line"></span><br><span class="line">	/* If neither context have a parent context; they cannot be clones. */</span><br><span class="line">	if (!parent &amp;&amp; !next_parent)</span><br><span class="line">		goto unlock;</span><br><span class="line"></span><br><span class="line">    /* (2.3.1) 如果curr task和next task的context刚好是parent关系，我们使用快捷路径来切换任务， </span><br><span class="line">        context的parent关系，只有在创建子进程，且所有的父进程event都有inherit属性被子进程全部复制继承，</span><br><span class="line">     */</span><br><span class="line">	if (next_parent == ctx || next_ctx == parent || next_parent == parent) &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * Looks like the two contexts are clones, so we might be</span><br><span class="line">		 * able to optimize the context switch.  We lock both</span><br><span class="line">		 * contexts and check that they are clones under the</span><br><span class="line">		 * lock (including re-checking that neither has been</span><br><span class="line">		 * uncloned in the meantime).  It doesn&apos;t matter which</span><br><span class="line">		 * order we take the locks because no other cpu could</span><br><span class="line">		 * be trying to lock both of these tasks.</span><br><span class="line">		 */</span><br><span class="line">		raw_spin_lock(&amp;ctx-&gt;lock);</span><br><span class="line">		raw_spin_lock_nested(&amp;next_ctx-&gt;lock, SINGLE_DEPTH_NESTING);</span><br><span class="line">		if (context_equiv(ctx, next_ctx)) &#123;</span><br><span class="line">			/*</span><br><span class="line">			 * XXX do we need a memory barrier of sorts</span><br><span class="line">			 * wrt to rcu_dereference() of perf_event_ctxp</span><br><span class="line">			 */</span><br><span class="line">			task-&gt;perf_event_ctxp[ctxn] = next_ctx;</span><br><span class="line">			next-&gt;perf_event_ctxp[ctxn] = ctx;</span><br><span class="line">			ctx-&gt;task = next;</span><br><span class="line">			next_ctx-&gt;task = task;</span><br><span class="line"></span><br><span class="line">			swap(ctx-&gt;task_ctx_data, next_ctx-&gt;task_ctx_data);</span><br><span class="line"></span><br><span class="line">			do_switch = 0;</span><br><span class="line"></span><br><span class="line">			perf_event_sync_stat(ctx, next_ctx);</span><br><span class="line">		&#125;</span><br><span class="line">		raw_spin_unlock(&amp;next_ctx-&gt;lock);</span><br><span class="line">		raw_spin_unlock(&amp;ctx-&gt;lock);</span><br><span class="line">	&#125;</span><br><span class="line">unlock:</span><br><span class="line">	rcu_read_unlock();</span><br><span class="line"></span><br><span class="line">    /* (2.3.2) 慢速路径的task context切换：</span><br><span class="line">     */</span><br><span class="line">	if (do_switch) &#123;</span><br><span class="line">		raw_spin_lock(&amp;ctx-&gt;lock);</span><br><span class="line">		ctx_sched_out(ctx, cpuctx, EVENT_ALL);</span><br><span class="line">		cpuctx-&gt;task_ctx = NULL;</span><br><span class="line">		raw_spin_unlock(&amp;ctx-&gt;lock);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||→</span><br><span class="line"></span><br><span class="line">static void ctx_sched_out(struct perf_event_context *ctx,</span><br><span class="line">			  struct perf_cpu_context *cpuctx,</span><br><span class="line">			  enum event_type_t event_type)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *event;</span><br><span class="line">	int is_active = ctx-&gt;is_active;</span><br><span class="line"></span><br><span class="line">	ctx-&gt;is_active &amp;= ~event_type;</span><br><span class="line">	if (likely(!ctx-&gt;nr_events))</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	update_context_time(ctx);</span><br><span class="line">	update_cgrp_time_from_cpuctx(cpuctx);</span><br><span class="line">	if (!ctx-&gt;nr_active)</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	perf_pmu_disable(ctx-&gt;pmu);</span><br><span class="line">	/* (2.3.2.1) 遍历context的高优先级event链表-&gt;pinned_groups：</span><br><span class="line">	    任务已经被切出，关联的所有event需要停工</span><br><span class="line">	 */</span><br><span class="line">	if ((is_active &amp; EVENT_PINNED) &amp;&amp; (event_type &amp; EVENT_PINNED)) &#123;</span><br><span class="line">		list_for_each_entry(event, &amp;ctx-&gt;pinned_groups, group_entry)</span><br><span class="line">			group_sched_out(event, cpuctx, ctx);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.3.2.2) 遍历context的低优先级event链表-&gt;flexible_groups：</span><br><span class="line">	    任务已经被切出，关联的所有event需要停工</span><br><span class="line">	 */</span><br><span class="line">	if ((is_active &amp; EVENT_FLEXIBLE) &amp;&amp; (event_type &amp; EVENT_FLEXIBLE)) &#123;</span><br><span class="line">		list_for_each_entry(event, &amp;ctx-&gt;flexible_groups, group_entry)</span><br><span class="line">			group_sched_out(event, cpuctx, ctx);</span><br><span class="line">	&#125;</span><br><span class="line">	perf_pmu_enable(ctx-&gt;pmu);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||||→</span><br><span class="line"></span><br><span class="line">static void</span><br><span class="line">group_sched_out(struct perf_event *group_event,</span><br><span class="line">		struct perf_cpu_context *cpuctx,</span><br><span class="line">		struct perf_event_context *ctx)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *event;</span><br><span class="line">	int state = group_event-&gt;state;</span><br><span class="line"></span><br><span class="line">    /* (2.3.2.2.1) 对group leader event进行停工 */</span><br><span class="line">	event_sched_out(group_event, cpuctx, ctx);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Schedule out siblings (if any):</span><br><span class="line">	 */</span><br><span class="line">	/* (2.3.2.2.2) 对group leader下的子event进行停工 */</span><br><span class="line">	list_for_each_entry(event, &amp;group_event-&gt;sibling_list, group_entry)</span><br><span class="line">		event_sched_out(event, cpuctx, ctx);</span><br><span class="line"></span><br><span class="line">	if (state == PERF_EVENT_STATE_ACTIVE &amp;&amp; group_event-&gt;attr.exclusive)</span><br><span class="line">		cpuctx-&gt;exclusive = 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||||→</span><br><span class="line"></span><br><span class="line">static void</span><br><span class="line">event_sched_out(struct perf_event *event,</span><br><span class="line">		  struct perf_cpu_context *cpuctx,</span><br><span class="line">		  struct perf_event_context *ctx)</span><br><span class="line">&#123;</span><br><span class="line">	u64 tstamp = perf_event_time(event);</span><br><span class="line">	u64 delta;</span><br><span class="line"></span><br><span class="line">	WARN_ON_ONCE(event-&gt;ctx != ctx);</span><br><span class="line">	lockdep_assert_held(&amp;ctx-&gt;lock);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * An event which could not be activated because of</span><br><span class="line">	 * filter mismatch still needs to have its timings</span><br><span class="line">	 * maintained, otherwise bogus information is return</span><br><span class="line">	 * via read() for time_enabled, time_running:</span><br><span class="line">	 */</span><br><span class="line">	if (event-&gt;state == PERF_EVENT_STATE_INACTIVE</span><br><span class="line">	    &amp;&amp; !event_filter_match(event)) &#123;</span><br><span class="line">		delta = tstamp - event-&gt;tstamp_stopped;</span><br><span class="line">		event-&gt;tstamp_running += delta;</span><br><span class="line">		event-&gt;tstamp_stopped = tstamp;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.3.2.2.1.1) 如果当前event不是开工状态(PERF_EVENT_STATE_ACTIVE)直接返回 */</span><br><span class="line">	if (event-&gt;state != PERF_EVENT_STATE_ACTIVE)</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	perf_pmu_disable(event-&gt;pmu);</span><br><span class="line"></span><br><span class="line">	event-&gt;tstamp_stopped = tstamp;</span><br><span class="line">	</span><br><span class="line">	/* (2.3.2.2.1.2) 调用event的停工函数：pmu-&gt;del() */</span><br><span class="line">	event-&gt;pmu-&gt;del(event, 0);</span><br><span class="line">	event-&gt;oncpu = -1;</span><br><span class="line">	</span><br><span class="line">	/* (2.3.2.2.1.3) 状态设置为停工：PERF_EVENT_STATE_INACTIVE */</span><br><span class="line">	event-&gt;state = PERF_EVENT_STATE_INACTIVE;</span><br><span class="line">	if (event-&gt;pending_disable) &#123;</span><br><span class="line">		event-&gt;pending_disable = 0;</span><br><span class="line">		event-&gt;state = PERF_EVENT_STATE_OFF;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (!is_software_event(event))</span><br><span class="line">		cpuctx-&gt;active_oncpu--;</span><br><span class="line">	if (!--ctx-&gt;nr_active)</span><br><span class="line">		perf_event_ctx_deactivate(ctx);</span><br><span class="line">	if (event-&gt;attr.freq &amp;&amp; event-&gt;attr.sample_freq)</span><br><span class="line">		ctx-&gt;nr_freq--;</span><br><span class="line">	if (event-&gt;attr.exclusive || !cpuctx-&gt;active_oncpu)</span><br><span class="line">		cpuctx-&gt;exclusive = 0;</span><br><span class="line"></span><br><span class="line">	if (is_orphaned_child(event))</span><br><span class="line">		schedule_orphans_remove(ctx);</span><br><span class="line"></span><br><span class="line">	perf_pmu_enable(event-&gt;pmu);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>context_switch() -&gt; finish_task_switch() -&gt; perf_event_task_sched_in():</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br></pre></td><td class="code"><pre><span class="line">static inline void perf_event_task_sched_in(struct task_struct *prev,</span><br><span class="line">					    struct task_struct *task)</span><br><span class="line">&#123;</span><br><span class="line">    /* (1) 新进程上相关的event需要开工 */</span><br><span class="line">	if (static_key_false(&amp;perf_sched_events.key))</span><br><span class="line">		__perf_event_task_sched_in(prev, task);</span><br><span class="line"></span><br><span class="line">	if (perf_sw_migrate_enabled() &amp;&amp; task-&gt;sched_migrated) &#123;</span><br><span class="line">		struct pt_regs *regs = this_cpu_ptr(&amp;__perf_regs[0]);</span><br><span class="line"></span><br><span class="line">		perf_fetch_caller_regs(regs);</span><br><span class="line">		___perf_sw_event(PERF_COUNT_SW_CPU_MIGRATIONS, 1, regs, 0);</span><br><span class="line">		task-&gt;sched_migrated = 0;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|→</span><br><span class="line"></span><br><span class="line">void __perf_event_task_sched_in(struct task_struct *prev,</span><br><span class="line">				struct task_struct *task)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event_context *ctx;</span><br><span class="line">	int ctxn;</span><br><span class="line"></span><br><span class="line">    /* (1.1) 遍历task-&gt;[perf_event_ctxp]中的context， </span><br><span class="line">        逐个打开context链接中的每个perf_event</span><br><span class="line">     */</span><br><span class="line">	for_each_task_context_nr(ctxn) &#123;</span><br><span class="line">		ctx = task-&gt;perf_event_ctxp[ctxn];</span><br><span class="line">		if (likely(!ctx))</span><br><span class="line">			continue;</span><br><span class="line"></span><br><span class="line">		perf_event_context_sched_in(ctx, task);</span><br><span class="line">	&#125;</span><br><span class="line">	/*</span><br><span class="line">	 * if cgroup events exist on this CPU, then we need</span><br><span class="line">	 * to check if we have to switch in PMU state.</span><br><span class="line">	 * cgroup event are system-wide mode only</span><br><span class="line">	 */</span><br><span class="line">	if (atomic_read(this_cpu_ptr(&amp;perf_cgroup_events)))</span><br><span class="line">		perf_cgroup_sched_in(prev, task);</span><br><span class="line"></span><br><span class="line">	if (atomic_read(&amp;nr_switch_events))</span><br><span class="line">		perf_event_switch(task, prev, true);</span><br><span class="line"></span><br><span class="line">	if (__this_cpu_read(perf_sched_cb_usages))</span><br><span class="line">		perf_pmu_sched_task(prev, task, true);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||→</span><br><span class="line"></span><br><span class="line">static void perf_event_context_sched_in(struct perf_event_context *ctx,</span><br><span class="line">					struct task_struct *task)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_cpu_context *cpuctx;</span><br><span class="line"></span><br><span class="line">	cpuctx = __get_cpu_context(ctx);</span><br><span class="line">	if (cpuctx-&gt;task_ctx == ctx)</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	perf_ctx_lock(cpuctx, ctx);</span><br><span class="line">	perf_pmu_disable(ctx-&gt;pmu);</span><br><span class="line">	/*</span><br><span class="line">	 * We want to keep the following priority order:</span><br><span class="line">	 * cpu pinned (that don&apos;t need to move), task pinned,</span><br><span class="line">	 * cpu flexible, task flexible.</span><br><span class="line">	 */</span><br><span class="line">	/* (1.1.1) 将新task context对应的本cpu维度的ctx-&gt;flexible_groups停工</span><br><span class="line">	    ctx-&gt;pinned_groups这时不会停工，就体现出优先级了？</span><br><span class="line">     */</span><br><span class="line">	cpu_ctx_sched_out(cpuctx, EVENT_FLEXIBLE);</span><br><span class="line"></span><br><span class="line">    /* (1.1.2) 切换本cpu的当前task context指针：cpuctx-&gt;task_ctx */</span><br><span class="line">	if (ctx-&gt;nr_events)</span><br><span class="line">		cpuctx-&gt;task_ctx = ctx;</span><br><span class="line"></span><br><span class="line">    /* (1.1.3) 将新对应的本cpu维度的ctx-&gt;flexible_groups开工 </span><br><span class="line">        将task context对应的ctx-&gt;flexible_groups、ctx-&gt;pinned_groups开工</span><br><span class="line">     */</span><br><span class="line">	perf_event_sched_in(cpuctx, cpuctx-&gt;task_ctx, task);</span><br><span class="line"></span><br><span class="line">	perf_pmu_enable(ctx-&gt;pmu);</span><br><span class="line">	perf_ctx_unlock(cpuctx, ctx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||→</span><br><span class="line"></span><br><span class="line">static void perf_event_sched_in(struct perf_cpu_context *cpuctx,</span><br><span class="line">				struct perf_event_context *ctx,</span><br><span class="line">				struct task_struct *task)</span><br><span class="line">&#123;</span><br><span class="line">	cpu_ctx_sched_in(cpuctx, EVENT_PINNED, task);</span><br><span class="line">	if (ctx)</span><br><span class="line">		ctx_sched_in(ctx, cpuctx, EVENT_PINNED, task);</span><br><span class="line">	cpu_ctx_sched_in(cpuctx, EVENT_FLEXIBLE, task);</span><br><span class="line">	if (ctx)</span><br><span class="line">		ctx_sched_in(ctx, cpuctx, EVENT_FLEXIBLE, task);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||||→</span><br><span class="line"></span><br><span class="line">static void cpu_ctx_sched_in(struct perf_cpu_context *cpuctx,</span><br><span class="line">			     enum event_type_t event_type,</span><br><span class="line">			     struct task_struct *task)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event_context *ctx = &amp;cpuctx-&gt;ctx;</span><br><span class="line"></span><br><span class="line">	ctx_sched_in(ctx, cpuctx, event_type, task);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||||→</span><br><span class="line"></span><br><span class="line">static void</span><br><span class="line">ctx_sched_in(struct perf_event_context *ctx,</span><br><span class="line">	     struct perf_cpu_context *cpuctx,</span><br><span class="line">	     enum event_type_t event_type,</span><br><span class="line">	     struct task_struct *task)</span><br><span class="line">&#123;</span><br><span class="line">	u64 now;</span><br><span class="line">	int is_active = ctx-&gt;is_active;</span><br><span class="line"></span><br><span class="line">	ctx-&gt;is_active |= event_type;</span><br><span class="line">	if (likely(!ctx-&gt;nr_events))</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	now = perf_clock();</span><br><span class="line">	ctx-&gt;timestamp = now;</span><br><span class="line">	perf_cgroup_set_timestamp(task, ctx);</span><br><span class="line">	/*</span><br><span class="line">	 * First go through the list and put on any pinned groups</span><br><span class="line">	 * in order to give them the best chance of going on.</span><br><span class="line">	 */</span><br><span class="line">	if (!(is_active &amp; EVENT_PINNED) &amp;&amp; (event_type &amp; EVENT_PINNED))</span><br><span class="line">		ctx_pinned_sched_in(ctx, cpuctx);</span><br><span class="line"></span><br><span class="line">	/* Then walk through the lower prio flexible groups */</span><br><span class="line">	if (!(is_active &amp; EVENT_FLEXIBLE) &amp;&amp; (event_type &amp; EVENT_FLEXIBLE))</span><br><span class="line">		ctx_flexible_sched_in(ctx, cpuctx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||||||→</span><br><span class="line"></span><br><span class="line">static void</span><br><span class="line">ctx_pinned_sched_in(struct perf_event_context *ctx,</span><br><span class="line">		    struct perf_cpu_context *cpuctx)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *event;</span><br><span class="line"></span><br><span class="line">	list_for_each_entry(event, &amp;ctx-&gt;pinned_groups, group_entry) &#123;</span><br><span class="line">		if (event-&gt;state &lt;= PERF_EVENT_STATE_OFF)</span><br><span class="line">			continue;</span><br><span class="line">		if (!event_filter_match(event))</span><br><span class="line">			continue;</span><br><span class="line"></span><br><span class="line">		/* may need to reset tstamp_enabled */</span><br><span class="line">		if (is_cgroup_event(event))</span><br><span class="line">			perf_cgroup_mark_enabled(event, ctx);</span><br><span class="line"></span><br><span class="line">		if (group_can_go_on(event, cpuctx, 1))</span><br><span class="line">			group_sched_in(event, cpuctx, ctx);</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * If this pinned group hasn&apos;t been scheduled,</span><br><span class="line">		 * put it in error state.</span><br><span class="line">		 */</span><br><span class="line">		if (event-&gt;state == PERF_EVENT_STATE_INACTIVE) &#123;</span><br><span class="line">			update_group_times(event);</span><br><span class="line">			event-&gt;state = PERF_EVENT_STATE_ERROR;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||||||→</span><br><span class="line"></span><br><span class="line">static int</span><br><span class="line">group_sched_in(struct perf_event *group_event,</span><br><span class="line">	       struct perf_cpu_context *cpuctx,</span><br><span class="line">	       struct perf_event_context *ctx)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *event, *partial_group = NULL;</span><br><span class="line">	struct pmu *pmu = ctx-&gt;pmu;</span><br><span class="line">	u64 now = ctx-&gt;time;</span><br><span class="line">	bool simulate = false;</span><br><span class="line"></span><br><span class="line">	if (group_event-&gt;state == PERF_EVENT_STATE_OFF)</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">	pmu-&gt;start_txn(pmu, PERF_PMU_TXN_ADD);</span><br><span class="line"></span><br><span class="line">	if (event_sched_in(group_event, cpuctx, ctx)) &#123;</span><br><span class="line">		pmu-&gt;cancel_txn(pmu);</span><br><span class="line">		perf_mux_hrtimer_restart(cpuctx);</span><br><span class="line">		return -EAGAIN;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Schedule in siblings as one group (if any):</span><br><span class="line">	 */</span><br><span class="line">	list_for_each_entry(event, &amp;group_event-&gt;sibling_list, group_entry) &#123;</span><br><span class="line">		if (event_sched_in(event, cpuctx, ctx)) &#123;</span><br><span class="line">			partial_group = event;</span><br><span class="line">			goto group_error;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (!pmu-&gt;commit_txn(pmu))</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">group_error:</span><br><span class="line">	/*</span><br><span class="line">	 * Groups can be scheduled in as one unit only, so undo any</span><br><span class="line">	 * partial group before returning:</span><br><span class="line">	 * The events up to the failed event are scheduled out normally,</span><br><span class="line">	 * tstamp_stopped will be updated.</span><br><span class="line">	 *</span><br><span class="line">	 * The failed events and the remaining siblings need to have</span><br><span class="line">	 * their timings updated as if they had gone thru event_sched_in()</span><br><span class="line">	 * and event_sched_out(). This is required to get consistent timings</span><br><span class="line">	 * across the group. This also takes care of the case where the group</span><br><span class="line">	 * could never be scheduled by ensuring tstamp_stopped is set to mark</span><br><span class="line">	 * the time the event was actually stopped, such that time delta</span><br><span class="line">	 * calculation in update_event_times() is correct.</span><br><span class="line">	 */</span><br><span class="line">	list_for_each_entry(event, &amp;group_event-&gt;sibling_list, group_entry) &#123;</span><br><span class="line">		if (event == partial_group)</span><br><span class="line">			simulate = true;</span><br><span class="line"></span><br><span class="line">		if (simulate) &#123;</span><br><span class="line">			event-&gt;tstamp_running += now - event-&gt;tstamp_stopped;</span><br><span class="line">			event-&gt;tstamp_stopped = now;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			event_sched_out(event, cpuctx, ctx);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	event_sched_out(group_event, cpuctx, ctx);</span><br><span class="line"></span><br><span class="line">	pmu-&gt;cancel_txn(pmu);</span><br><span class="line"></span><br><span class="line">	perf_mux_hrtimer_restart(cpuctx);</span><br><span class="line"></span><br><span class="line">	return -EAGAIN;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||||||||→</span><br><span class="line"></span><br><span class="line">static int</span><br><span class="line">event_sched_in(struct perf_event *event,</span><br><span class="line">		 struct perf_cpu_context *cpuctx,</span><br><span class="line">		 struct perf_event_context *ctx)</span><br><span class="line">&#123;</span><br><span class="line">	u64 tstamp = perf_event_time(event);</span><br><span class="line">	int ret = 0;</span><br><span class="line"></span><br><span class="line">	lockdep_assert_held(&amp;ctx-&gt;lock);</span><br><span class="line"></span><br><span class="line">	if (event-&gt;state &lt;= PERF_EVENT_STATE_OFF)</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">	WRITE_ONCE(event-&gt;oncpu, smp_processor_id());</span><br><span class="line">	/*</span><br><span class="line">	 * Order event::oncpu write to happen before the ACTIVE state</span><br><span class="line">	 * is visible.</span><br><span class="line">	 */</span><br><span class="line">	/* 设置event为开工状态：PERF_EVENT_STATE_ACTIVE */</span><br><span class="line">	smp_wmb();</span><br><span class="line">	WRITE_ONCE(event-&gt;state, PERF_EVENT_STATE_ACTIVE);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Unthrottle events, since we scheduled we might have missed several</span><br><span class="line">	 * ticks already, also for a heavily scheduling task there is little</span><br><span class="line">	 * guarantee it&apos;ll get a tick in a timely manner.</span><br><span class="line">	 */</span><br><span class="line">	if (unlikely(event-&gt;hw.interrupts == MAX_INTERRUPTS)) &#123;</span><br><span class="line">		perf_log_throttle(event, 1);</span><br><span class="line">		event-&gt;hw.interrupts = 0;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * The new state must be visible before we turn it on in the hardware:</span><br><span class="line">	 */</span><br><span class="line">	smp_wmb();</span><br><span class="line"></span><br><span class="line">	perf_pmu_disable(event-&gt;pmu);</span><br><span class="line"></span><br><span class="line">	perf_set_shadow_time(event, ctx, tstamp);</span><br><span class="line"></span><br><span class="line">	perf_log_itrace_start(event);</span><br><span class="line"></span><br><span class="line">    /* 调用event的开工函数：pmu-&gt;add() */</span><br><span class="line">	if (event-&gt;pmu-&gt;add(event, PERF_EF_START)) &#123;</span><br><span class="line">		event-&gt;state = PERF_EVENT_STATE_INACTIVE;</span><br><span class="line">		event-&gt;oncpu = -1;</span><br><span class="line">		ret = -EAGAIN;</span><br><span class="line">		goto out;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	event-&gt;tstamp_running += tstamp - event-&gt;tstamp_stopped;</span><br><span class="line"></span><br><span class="line">	if (!is_software_event(event))</span><br><span class="line">		cpuctx-&gt;active_oncpu++;</span><br><span class="line">	if (!ctx-&gt;nr_active++)</span><br><span class="line">		perf_event_ctx_activate(ctx);</span><br><span class="line">	if (event-&gt;attr.freq &amp;&amp; event-&gt;attr.sample_freq)</span><br><span class="line">		ctx-&gt;nr_freq++;</span><br><span class="line"></span><br><span class="line">	if (event-&gt;attr.exclusive)</span><br><span class="line">		cpuctx-&gt;exclusive = 1;</span><br><span class="line"></span><br><span class="line">	if (is_orphaned_child(event))</span><br><span class="line">		schedule_orphans_remove(ctx);</span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">	perf_pmu_enable(event-&gt;pmu);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果是pid&gt;0，cpu!=-1的event，在sched_in的时候会调用event_filter_match()判断当前cpu和event绑定的cpu(event-&gt;cpu)是否一致，只有符合条件event才能被使能：</p>
<p>ctx_pinned_sched_in()/ctx_flexible_sched_in() -&gt; event_filter_match()：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">static inline int</span><br><span class="line">event_filter_match(struct perf_event *event)</span><br><span class="line">&#123;</span><br><span class="line">    /* 如果没有指定cpu：event-&gt;cpu == -1 </span><br><span class="line">        或者event绑定cpu和当前cpu一致：event-&gt;cpu == smp_processor_id()</span><br><span class="line">        cgroup的filter条件：perf_cgroup_match(event)</span><br><span class="line">        pmu的filter条件：pmu_filter_match(event)</span><br><span class="line">        上述条件符合的情况下，才能event才能被使能</span><br><span class="line">     */</span><br><span class="line">	return (event-&gt;cpu == -1 || event-&gt;cpu == smp_processor_id())</span><br><span class="line">	    &amp;&amp; perf_cgroup_match(event) &amp;&amp; pmu_filter_match(event);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-3、cgroup"><a href="#2-3、cgroup" class="headerlink" title="2.3、cgroup"></a>2.3、cgroup</h2><p>暂不分析</p>
<h1 id="3、perf-ioctl"><a href="#3、perf-ioctl" class="headerlink" title="3、perf_ioctl"></a>3、perf_ioctl</h1><p>通过perf_event_open()系统调用获得perf_event对应的fd后，可以通过操作fd的ioctl命令来配置perf_event。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">static long perf_ioctl(struct file *file, unsigned int cmd, unsigned long arg)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *event = file-&gt;private_data;</span><br><span class="line">	struct perf_event_context *ctx;</span><br><span class="line">	long ret;</span><br><span class="line"></span><br><span class="line">	ctx = perf_event_ctx_lock(event);</span><br><span class="line">	ret = _perf_ioctl(event, cmd, arg);</span><br><span class="line">	perf_event_ctx_unlock(event, ctx);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">↓</span><br><span class="line"></span><br><span class="line">static long _perf_ioctl(struct perf_event *event, unsigned int cmd, unsigned long arg)</span><br><span class="line">&#123;</span><br><span class="line">	void (*func)(struct perf_event *);</span><br><span class="line">	u32 flags = arg;</span><br><span class="line"></span><br><span class="line">	switch (cmd) &#123;</span><br><span class="line">	case PERF_EVENT_IOC_ENABLE:</span><br><span class="line">		func = _perf_event_enable;</span><br><span class="line">		break;</span><br><span class="line">	case PERF_EVENT_IOC_DISABLE:</span><br><span class="line">		func = _perf_event_disable;</span><br><span class="line">		break;</span><br><span class="line">	case PERF_EVENT_IOC_RESET:</span><br><span class="line">		func = _perf_event_reset;</span><br><span class="line">		break;</span><br><span class="line"></span><br><span class="line">	case PERF_EVENT_IOC_REFRESH:</span><br><span class="line">		return _perf_event_refresh(event, arg);</span><br><span class="line"></span><br><span class="line">	case PERF_EVENT_IOC_PERIOD:</span><br><span class="line">		return perf_event_period(event, (u64 __user *)arg);</span><br><span class="line"></span><br><span class="line">	case PERF_EVENT_IOC_ID:</span><br><span class="line">	&#123;</span><br><span class="line">		u64 id = primary_event_id(event);</span><br><span class="line"></span><br><span class="line">		if (copy_to_user((void __user *)arg, &amp;id, sizeof(id)))</span><br><span class="line">			return -EFAULT;</span><br><span class="line">		return 0;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	case PERF_EVENT_IOC_SET_OUTPUT:</span><br><span class="line">	&#123;</span><br><span class="line">		int ret;</span><br><span class="line">		if (arg != -1) &#123;</span><br><span class="line">			struct perf_event *output_event;</span><br><span class="line">			struct fd output;</span><br><span class="line">			ret = perf_fget_light(arg, &amp;output);</span><br><span class="line">			if (ret)</span><br><span class="line">				return ret;</span><br><span class="line">			output_event = output.file-&gt;private_data;</span><br><span class="line">			ret = perf_event_set_output(event, output_event);</span><br><span class="line">			fdput(output);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			ret = perf_event_set_output(event, NULL);</span><br><span class="line">		&#125;</span><br><span class="line">		return ret;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	case PERF_EVENT_IOC_SET_FILTER:</span><br><span class="line">		return perf_event_set_filter(event, (void __user *)arg);</span><br><span class="line"></span><br><span class="line">	case PERF_EVENT_IOC_SET_BPF:</span><br><span class="line">		return perf_event_set_bpf_prog(event, arg);</span><br><span class="line"></span><br><span class="line">	case PERF_EVENT_IOC_SET_DRV_CONFIGS:</span><br><span class="line">		return perf_event_drv_configs(event, (void __user *)arg);</span><br><span class="line"></span><br><span class="line">	default:</span><br><span class="line">		return -ENOTTY;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (flags &amp; PERF_IOC_FLAG_GROUP)</span><br><span class="line">		perf_event_for_each(event, func);</span><br><span class="line">	else</span><br><span class="line">		perf_event_for_each_child(event, func);</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-1、-perf-event-enable"><a href="#3-1、-perf-event-enable" class="headerlink" title="3.1、_perf_event_enable"></a>3.1、_perf_event_enable</h2><p>简单分析一下enable命令。该命令的主要作用就是把处于PERF_EVENT_STATE_OFF状态的event设置成PERF_EVENT_STATE_INACTIVE，以便该event能参与到perf sched当中去。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">static void _perf_event_enable(struct perf_event *event)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event_context *ctx = event-&gt;ctx;</span><br><span class="line">	struct task_struct *task = ctx-&gt;task;</span><br><span class="line"></span><br><span class="line">	if (!task) &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * Enable the event on the cpu that it&apos;s on</span><br><span class="line">		 */</span><br><span class="line">		cpu_function_call(event-&gt;cpu, __perf_event_enable, event);</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	raw_spin_lock_irq(&amp;ctx-&gt;lock);</span><br><span class="line">	if (event-&gt;state &gt;= PERF_EVENT_STATE_INACTIVE)</span><br><span class="line">		goto out;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * If the event is in error state, clear that first.</span><br><span class="line">	 * That way, if we see the event in error state below, we</span><br><span class="line">	 * know that it has gone back into error state, as distinct</span><br><span class="line">	 * from the task having been scheduled away before the</span><br><span class="line">	 * cross-call arrived.</span><br><span class="line">	 */</span><br><span class="line">	if (event-&gt;state == PERF_EVENT_STATE_ERROR)</span><br><span class="line">		event-&gt;state = PERF_EVENT_STATE_OFF;</span><br><span class="line"></span><br><span class="line">retry:</span><br><span class="line">	if (!ctx-&gt;is_active) &#123;</span><br><span class="line">		__perf_event_mark_enabled(event);</span><br><span class="line">		goto out;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	raw_spin_unlock_irq(&amp;ctx-&gt;lock);</span><br><span class="line"></span><br><span class="line">	if (!task_function_call(task, __perf_event_enable, event))</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	raw_spin_lock_irq(&amp;ctx-&gt;lock);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * If the context is active and the event is still off,</span><br><span class="line">	 * we need to retry the cross-call.</span><br><span class="line">	 */</span><br><span class="line">	if (ctx-&gt;is_active &amp;&amp; event-&gt;state == PERF_EVENT_STATE_OFF) &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * task could have been flipped by a concurrent</span><br><span class="line">		 * perf_event_context_sched_out()</span><br><span class="line">		 */</span><br><span class="line">		task = ctx-&gt;task;</span><br><span class="line">		goto retry;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">	raw_spin_unlock_irq(&amp;ctx-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">↓</span><br><span class="line"></span><br><span class="line">static void __perf_event_mark_enabled(struct perf_event *event)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *sub;</span><br><span class="line">	u64 tstamp = perf_event_time(event);</span><br><span class="line"></span><br><span class="line">	event-&gt;state = PERF_EVENT_STATE_INACTIVE;</span><br><span class="line">	event-&gt;tstamp_enabled = tstamp - event-&gt;total_time_enabled;</span><br><span class="line">	list_for_each_entry(sub, &amp;event-&gt;sibling_list, group_entry) &#123;</span><br><span class="line">		if (sub-&gt;state &gt;= PERF_EVENT_STATE_INACTIVE)</span><br><span class="line">			sub-&gt;tstamp_enabled = tstamp - sub-&gt;total_time_enabled;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外也可以设置attr.enable_on_exec，在执行exec()新的应用时enable perf_event。</p>
<p>load_elf_binary() -&gt; setup_new_exec() -&gt; perf_event_exec() -&gt; perf_event_enable_on_exec() -&gt; event_enable_on_exec()：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">static int event_enable_on_exec(struct perf_event *event,</span><br><span class="line">				struct perf_event_context *ctx)</span><br><span class="line">&#123;</span><br><span class="line">	if (!event-&gt;attr.enable_on_exec)</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">	event-&gt;attr.enable_on_exec = 0;</span><br><span class="line">	if (event-&gt;state &gt;= PERF_EVENT_STATE_INACTIVE)</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">	__perf_event_mark_enabled(event);</span><br><span class="line"></span><br><span class="line">	return 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="4、perf-read"><a href="#4、perf-read" class="headerlink" title="4、perf_read"></a>4、perf_read</h1><p>perf_event提供两种类型的信息：counter和sample。其中counter类型的数据就是通过read()操作读取的，最后会调到perf_read()函数。</p>
<p>需要重点关注一下group方式的读并累加：它会读取所有相关的perf_event的count，并且累加起来。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><span class="line">static ssize_t</span><br><span class="line">perf_read(struct file *file, char __user *buf, size_t count, loff_t *ppos)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *event = file-&gt;private_data;</span><br><span class="line">	struct perf_event_context *ctx;</span><br><span class="line">	int ret;</span><br><span class="line"></span><br><span class="line">	ctx = perf_event_ctx_lock(event);</span><br><span class="line">	ret = __perf_read(event, buf, count);</span><br><span class="line">	perf_event_ctx_unlock(event, ctx);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">↓</span><br><span class="line"></span><br><span class="line">static ssize_t</span><br><span class="line">__perf_read(struct perf_event *event, char __user *buf, size_t count)</span><br><span class="line">&#123;</span><br><span class="line">    /* (1) 读取attr.read_format */</span><br><span class="line">	u64 read_format = event-&gt;attr.read_format;</span><br><span class="line">	int ret;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Return end-of-file for a read on a event that is in</span><br><span class="line">	 * error state (i.e. because it was pinned but it couldn&apos;t be</span><br><span class="line">	 * scheduled on to the CPU at some point).</span><br><span class="line">	 */</span><br><span class="line">	if (event-&gt;state == PERF_EVENT_STATE_ERROR)</span><br><span class="line">		return 0;</span><br><span class="line"></span><br><span class="line">	if (count &lt; event-&gt;read_size)</span><br><span class="line">		return -ENOSPC;</span><br><span class="line"></span><br><span class="line">	WARN_ON_ONCE(event-&gt;ctx-&gt;parent_ctx);</span><br><span class="line">	/* (2) 如果是PERF_FORMAT_GROUP，本event为group_leader， </span><br><span class="line">	    读取本event的count，以及group所有子event的count</span><br><span class="line">	 */</span><br><span class="line">	if (read_format &amp; PERF_FORMAT_GROUP)</span><br><span class="line">		ret = perf_read_group(event, read_format, buf);</span><br><span class="line">	/* (3) 仅仅读取本event的count */</span><br><span class="line">	else</span><br><span class="line">		ret = perf_read_one(event, read_format, buf);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|→</span><br><span class="line"></span><br><span class="line">static int perf_read_group(struct perf_event *event,</span><br><span class="line">				   u64 read_format, char __user *buf)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *leader = event-&gt;group_leader, *child;</span><br><span class="line">	struct perf_event_context *ctx = leader-&gt;ctx;</span><br><span class="line">	int ret;</span><br><span class="line">	u64 *values;</span><br><span class="line"></span><br><span class="line">	lockdep_assert_held(&amp;ctx-&gt;mutex);</span><br><span class="line"></span><br><span class="line">    /* (2.1) 分配存储group中所有event count需要的空间 */</span><br><span class="line">	values = kzalloc(event-&gt;read_size, GFP_KERNEL);</span><br><span class="line">	if (!values)</span><br><span class="line">		return -ENOMEM;</span><br><span class="line"></span><br><span class="line">    /* (2.2) 第一个字节保存event的个数 */</span><br><span class="line">	values[0] = 1 + leader-&gt;nr_siblings;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * By locking the child_mutex of the leader we effectively</span><br><span class="line">	 * lock the child list of all siblings.. XXX explain how.</span><br><span class="line">	 */</span><br><span class="line">	mutex_lock(&amp;leader-&gt;child_mutex);</span><br><span class="line"></span><br><span class="line">    /* (2.4) 遍历本group_leader的event以及所有子event，读取并累加count */</span><br><span class="line">	ret = __perf_read_group_add(leader, read_format, values);</span><br><span class="line">	if (ret)</span><br><span class="line">		goto unlock;</span><br><span class="line"></span><br><span class="line">    /* (2.5) 遍历所有子进程inherit的group leader，读取并累加count */</span><br><span class="line">	list_for_each_entry(child, &amp;leader-&gt;child_list, child_list) &#123;</span><br><span class="line">		ret = __perf_read_group_add(child, read_format, values);</span><br><span class="line">		if (ret)</span><br><span class="line">			goto unlock;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	mutex_unlock(&amp;leader-&gt;child_mutex);</span><br><span class="line"></span><br><span class="line">    /* (2.6) 拷贝count内容到用户态 */</span><br><span class="line">	ret = event-&gt;read_size;</span><br><span class="line">	if (copy_to_user(buf, values, event-&gt;read_size))</span><br><span class="line">		ret = -EFAULT;</span><br><span class="line">	goto out;</span><br><span class="line"></span><br><span class="line">unlock:</span><br><span class="line">	mutex_unlock(&amp;leader-&gt;child_mutex);</span><br><span class="line">out:</span><br><span class="line">	kfree(values);</span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">||→</span><br><span class="line"></span><br><span class="line">static int __perf_read_group_add(struct perf_event *leader,</span><br><span class="line">					u64 read_format, u64 *values)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *sub;</span><br><span class="line">	int n = 1; /* skip @nr */</span><br><span class="line">	int ret;</span><br><span class="line"></span><br><span class="line">    /* (2.4.1) 准备好数据：硬件counter从寄存器中读出count保存到event结构中 </span><br><span class="line">        如果event正在运行尝试更新最新的数据</span><br><span class="line">     */</span><br><span class="line">	ret = perf_event_read(leader, true);</span><br><span class="line">	if (ret)</span><br><span class="line">		return ret;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Since we co-schedule groups, &#123;enabled,running&#125; times of siblings</span><br><span class="line">	 * will be identical to those of the leader, so we only publish one</span><br><span class="line">	 * set.</span><br><span class="line">	 */</span><br><span class="line">	/* (2.4.2) 读取enable time并累加：</span><br><span class="line">	    leader-&gt;total_time_enabled：本perf_event的值</span><br><span class="line">	    leader-&gt;child_total_time_enabled：inherit创建的子进程，如果子进程退出把值累加到父进程这里</span><br><span class="line">	 */</span><br><span class="line">	if (read_format &amp; PERF_FORMAT_TOTAL_TIME_ENABLED) &#123;</span><br><span class="line">		values[n++] += leader-&gt;total_time_enabled +</span><br><span class="line">			atomic64_read(&amp;leader-&gt;child_total_time_enabled);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    /* (2.4.3) 读取running time并累加 */</span><br><span class="line">	if (read_format &amp; PERF_FORMAT_TOTAL_TIME_RUNNING) &#123;</span><br><span class="line">		values[n++] += leader-&gt;total_time_running +</span><br><span class="line">			atomic64_read(&amp;leader-&gt;child_total_time_running);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Write &#123;count,id&#125; tuples for every sibling.</span><br><span class="line">	 */</span><br><span class="line">	/* (2.4.4) 读取group leader的count并累加 */</span><br><span class="line">	values[n++] += perf_event_count(leader);</span><br><span class="line">	if (read_format &amp; PERF_FORMAT_ID)</span><br><span class="line">		values[n++] = primary_event_id(leader);</span><br><span class="line"></span><br><span class="line">    /* (2.4.5) 逐个读取group member的count并累加 */</span><br><span class="line">	list_for_each_entry(sub, &amp;leader-&gt;sibling_list, group_entry) &#123;</span><br><span class="line">		values[n++] += perf_event_count(sub);</span><br><span class="line">		if (read_format &amp; PERF_FORMAT_ID)</span><br><span class="line">			values[n++] = primary_event_id(sub);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">|||→</span><br><span class="line"></span><br><span class="line">static int perf_event_read(struct perf_event *event, bool group)</span><br><span class="line">&#123;</span><br><span class="line">	int ret = 0;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * If event is enabled and currently active on a CPU, update the</span><br><span class="line">	 * value in the event structure:</span><br><span class="line">	 */</span><br><span class="line">	/* (2.4.1.1) 如果event正在运行尝试更新最新的数据 */</span><br><span class="line">	if (event-&gt;state == PERF_EVENT_STATE_ACTIVE &amp;&amp;</span><br><span class="line">						!cpu_isolated(event-&gt;oncpu)) &#123;</span><br><span class="line">		struct perf_read_data data = &#123;</span><br><span class="line">			.event = event,</span><br><span class="line">			.group = group,</span><br><span class="line">			.ret = 0,</span><br><span class="line">		&#125;;</span><br><span class="line">		if (!event-&gt;attr.exclude_idle ||</span><br><span class="line">					!per_cpu(is_idle, event-&gt;oncpu)) &#123;</span><br><span class="line">			smp_call_function_single(event-&gt;oncpu,</span><br><span class="line">				__perf_event_read, &amp;data, 1);</span><br><span class="line">			ret = data.ret;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; else if (event-&gt;state == PERF_EVENT_STATE_INACTIVE) &#123;</span><br><span class="line">		struct perf_event_context *ctx = event-&gt;ctx;</span><br><span class="line">		unsigned long flags;</span><br><span class="line"></span><br><span class="line">		raw_spin_lock_irqsave(&amp;ctx-&gt;lock, flags);</span><br><span class="line">		/*</span><br><span class="line">		 * may read while context is not active</span><br><span class="line">		 * (e.g., thread is blocked), in that case</span><br><span class="line">		 * we cannot update context time</span><br><span class="line">		 */</span><br><span class="line">		if (ctx-&gt;is_active) &#123;</span><br><span class="line">			update_context_time(ctx);</span><br><span class="line">			update_cgrp_time_from_event(event);</span><br><span class="line">		&#125;</span><br><span class="line">		if (group)</span><br><span class="line">			update_group_times(event);</span><br><span class="line">		else</span><br><span class="line">			update_event_times(event);</span><br><span class="line">		raw_spin_unlock_irqrestore(&amp;ctx-&gt;lock, flags);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="5、perf-mmap"><a href="#5、perf-mmap" class="headerlink" title="5、perf_mmap"></a>5、perf_mmap</h1><p>如果需要读取perf_event的sample类型的数据，需要先给perf_event分配一个对应的ringbuffer，为了减少开销这个ringbuffer会被mmap映射成用户态地址。</p>
<p>所以分配ringbuffer空间和映射成用户态地址这个两个操作都在perf_mmap()函数中完成。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br></pre></td><td class="code"><pre><span class="line">static int perf_mmap(struct file *file, struct vm_area_struct *vma)</span><br><span class="line">&#123;</span><br><span class="line">	struct perf_event *event = file-&gt;private_data;</span><br><span class="line">	unsigned long user_locked, user_lock_limit;</span><br><span class="line">	struct user_struct *user = current_user();</span><br><span class="line">	unsigned long locked, lock_limit;</span><br><span class="line">	struct ring_buffer *rb = NULL;</span><br><span class="line">	unsigned long vma_size;</span><br><span class="line">	unsigned long nr_pages;</span><br><span class="line">	long user_extra = 0, extra = 0;</span><br><span class="line">	int ret = 0, flags = 0;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Don&apos;t allow mmap() of inherited per-task counters. This would</span><br><span class="line">	 * create a performance issue due to all children writing to the</span><br><span class="line">	 * same rb.</span><br><span class="line">	 *</span><br><span class="line">	/* (1) 担心数据量过大 */</span><br><span class="line">	if (event-&gt;cpu == -1 &amp;&amp; event-&gt;attr.inherit)</span><br><span class="line">		return -EINVAL;</span><br><span class="line"></span><br><span class="line">	if (!(vma-&gt;vm_flags &amp; VM_SHARED))</span><br><span class="line">		return -EINVAL;</span><br><span class="line"></span><br><span class="line">	vma_size = vma-&gt;vm_end - vma-&gt;vm_start;</span><br><span class="line"></span><br><span class="line">    /* (2.1) 第一次mmap，必须是映射data区域, </span><br><span class="line">        size = (1 + 2^n)pages</span><br><span class="line">     */</span><br><span class="line">	if (vma-&gt;vm_pgoff == 0) &#123;</span><br><span class="line">		nr_pages = (vma_size / PAGE_SIZE) - 1;</span><br><span class="line">		</span><br><span class="line">	/* (2.2) 第二次mmap，可以映射aux data区域 */</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		/*</span><br><span class="line">		 * AUX area mapping: if rb-&gt;aux_nr_pages != 0, it&apos;s already</span><br><span class="line">		 * mapped, all subsequent mappings should have the same size</span><br><span class="line">		 * and offset. Must be above the normal perf buffer.</span><br><span class="line">		 */</span><br><span class="line">		u64 aux_offset, aux_size;</span><br><span class="line"></span><br><span class="line">		if (!event-&gt;rb)</span><br><span class="line">			return -EINVAL;</span><br><span class="line"></span><br><span class="line">		nr_pages = vma_size / PAGE_SIZE;</span><br><span class="line"></span><br><span class="line">		mutex_lock(&amp;event-&gt;mmap_mutex);</span><br><span class="line">		ret = -EINVAL;</span><br><span class="line"></span><br><span class="line">		rb = event-&gt;rb;</span><br><span class="line">		if (!rb)</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		aux_offset = ACCESS_ONCE(rb-&gt;user_page-&gt;aux_offset);</span><br><span class="line">		aux_size = ACCESS_ONCE(rb-&gt;user_page-&gt;aux_size);</span><br><span class="line"></span><br><span class="line">		if (aux_offset &lt; perf_data_size(rb) + PAGE_SIZE)</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		if (aux_offset != vma-&gt;vm_pgoff &lt;&lt; PAGE_SHIFT)</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		/* already mapped with a different offset */</span><br><span class="line">		if (rb_has_aux(rb) &amp;&amp; rb-&gt;aux_pgoff != vma-&gt;vm_pgoff)</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		if (aux_size != vma_size || aux_size != nr_pages * PAGE_SIZE)</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		/* already mapped with a different size */</span><br><span class="line">		if (rb_has_aux(rb) &amp;&amp; rb-&gt;aux_nr_pages != nr_pages)</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		if (!is_power_of_2(nr_pages))</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		if (!atomic_inc_not_zero(&amp;rb-&gt;mmap_count))</span><br><span class="line">			goto aux_unlock;</span><br><span class="line"></span><br><span class="line">		if (rb_has_aux(rb)) &#123;</span><br><span class="line">			atomic_inc(&amp;rb-&gt;aux_mmap_count);</span><br><span class="line">			ret = 0;</span><br><span class="line">			goto unlock;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		atomic_set(&amp;rb-&gt;aux_mmap_count, 1);</span><br><span class="line">		user_extra = nr_pages;</span><br><span class="line"></span><br><span class="line">		goto accounting;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * If we have rb pages ensure they&apos;re a power-of-two number, so we</span><br><span class="line">	 * can do bitmasks instead of modulo.</span><br><span class="line">	 */</span><br><span class="line">	if (nr_pages != 0 &amp;&amp; !is_power_of_2(nr_pages))</span><br><span class="line">		return -EINVAL;</span><br><span class="line"></span><br><span class="line">	if (vma_size != PAGE_SIZE * (1 + nr_pages))</span><br><span class="line">		return -EINVAL;</span><br><span class="line"></span><br><span class="line">	WARN_ON_ONCE(event-&gt;ctx-&gt;parent_ctx);</span><br><span class="line">again:</span><br><span class="line">	mutex_lock(&amp;event-&gt;mmap_mutex);</span><br><span class="line">	if (event-&gt;rb) &#123;</span><br><span class="line">		if (event-&gt;rb-&gt;nr_pages != nr_pages) &#123;</span><br><span class="line">			ret = -EINVAL;</span><br><span class="line">			goto unlock;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (!atomic_inc_not_zero(&amp;event-&gt;rb-&gt;mmap_count)) &#123;</span><br><span class="line">			/*</span><br><span class="line">			 * Raced against perf_mmap_close() through</span><br><span class="line">			 * perf_event_set_output(). Try again, hope for better</span><br><span class="line">			 * luck.</span><br><span class="line">			 */</span><br><span class="line">			mutex_unlock(&amp;event-&gt;mmap_mutex);</span><br><span class="line">			goto again;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		goto unlock;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	user_extra = nr_pages + 1;</span><br><span class="line"></span><br><span class="line">accounting:</span><br><span class="line">	user_lock_limit = sysctl_perf_event_mlock &gt;&gt; (PAGE_SHIFT - 10);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Increase the limit linearly with more CPUs:</span><br><span class="line">	 */</span><br><span class="line">	user_lock_limit *= num_online_cpus();</span><br><span class="line"></span><br><span class="line">	user_locked = atomic_long_read(&amp;user-&gt;locked_vm) + user_extra;</span><br><span class="line"></span><br><span class="line">	if (user_locked &gt; user_lock_limit)</span><br><span class="line">		extra = user_locked - user_lock_limit;</span><br><span class="line"></span><br><span class="line">	lock_limit = rlimit(RLIMIT_MEMLOCK);</span><br><span class="line">	lock_limit &gt;&gt;= PAGE_SHIFT;</span><br><span class="line">	locked = vma-&gt;vm_mm-&gt;pinned_vm + extra;</span><br><span class="line"></span><br><span class="line">	if ((locked &gt; lock_limit) &amp;&amp; perf_paranoid_tracepoint_raw() &amp;&amp;</span><br><span class="line">		!capable(CAP_IPC_LOCK)) &#123;</span><br><span class="line">		ret = -EPERM;</span><br><span class="line">		goto unlock;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	WARN_ON(!rb &amp;&amp; event-&gt;rb);</span><br><span class="line"></span><br><span class="line">	if (vma-&gt;vm_flags &amp; VM_WRITE)</span><br><span class="line">		flags |= RING_BUFFER_WRITABLE;</span><br><span class="line"></span><br><span class="line">    /* (3) 分配ringbuffer */</span><br><span class="line">	if (!rb) &#123;</span><br><span class="line">		rb = rb_alloc(nr_pages,</span><br><span class="line">			      event-&gt;attr.watermark ? event-&gt;attr.wakeup_watermark : 0,</span><br><span class="line">			      event-&gt;cpu, flags);</span><br><span class="line"></span><br><span class="line">		if (!rb) &#123;</span><br><span class="line">			ret = -ENOMEM;</span><br><span class="line">			goto unlock;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		atomic_set(&amp;rb-&gt;mmap_count, 1);</span><br><span class="line">		rb-&gt;mmap_user = get_current_user();</span><br><span class="line">		rb-&gt;mmap_locked = extra;</span><br><span class="line"></span><br><span class="line">        /* (3.1) 绑定rb到event */</span><br><span class="line">		ring_buffer_attach(event, rb);</span><br><span class="line"></span><br><span class="line">		perf_event_init_userpage(event);</span><br><span class="line">		perf_event_update_userpage(event);</span><br><span class="line">		</span><br><span class="line">	/* (4) 分配aux区域 */</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		ret = rb_alloc_aux(rb, event, vma-&gt;vm_pgoff, nr_pages,</span><br><span class="line">				   event-&gt;attr.aux_watermark, flags);</span><br><span class="line">		if (!ret)</span><br><span class="line">			rb-&gt;aux_mmap_locked = extra;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">unlock:</span><br><span class="line">	if (!ret) &#123;</span><br><span class="line">		atomic_long_add(user_extra, &amp;user-&gt;locked_vm);</span><br><span class="line">		vma-&gt;vm_mm-&gt;pinned_vm += extra;</span><br><span class="line"></span><br><span class="line">		atomic_inc(&amp;event-&gt;mmap_count);</span><br><span class="line">	&#125; else if (rb) &#123;</span><br><span class="line">		atomic_dec(&amp;rb-&gt;mmap_count);</span><br><span class="line">	&#125;</span><br><span class="line">aux_unlock:</span><br><span class="line">	mutex_unlock(&amp;event-&gt;mmap_mutex);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Since pinned accounting is per vm we cannot allow fork() to copy our</span><br><span class="line">	 * vma.</span><br><span class="line">	 */</span><br><span class="line">	vma-&gt;vm_flags |= VM_DONTCOPY | VM_DONTEXPAND | VM_DONTDUMP;</span><br><span class="line">	</span><br><span class="line">	/* (5) 给mmap的ops赋值 */</span><br><span class="line">	vma-&gt;vm_ops = &amp;perf_mmap_vmops;</span><br><span class="line"></span><br><span class="line">	if (event-&gt;pmu-&gt;event_mapped)</span><br><span class="line">		event-&gt;pmu-&gt;event_mapped(event);</span><br><span class="line"></span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><p><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/perf/design.txt" target="_blank" rel="noopener">1、Performance Counters for Linux</a></p>
<p><a href="https://www.kernel.org/doc/html/latest/trace/tracepoint-analysis.html" target="_blank" rel="noopener">2、Notes on Analysing Behaviour Using Events and Tracepoints</a></p>
<p><a href="https://www.cnblogs.com/arnoldlu/p/6241297.html" target="_blank" rel="noopener">3、系统级性能分析工具perf的介绍与使用</a></p>
<p><a href="http://www.a-site.cn/article/480590.html" target="_blank" rel="noopener">4、性能分析工具—Perf简介汇总整理 </a></p>
<p><a href="https://blog.csdn.net/he11o_liu/article/details/80361542" target="_blank" rel="noopener">5、Linux 性能检测/调优之Perf_Event</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/perf/" rel="tag"># perf</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/21/ftrace_tracer/" rel="next" title="Linux Ftrace 1.3、tracer (function、function_graph、irq_off)">
                <i class="fa fa-chevron-left"></i> Linux Ftrace 1.3、tracer (function、function_graph、irq_off)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/12/21/linux_time/" rel="prev" title="Linux Time">
                Linux Time <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/touxiang/ycqs.jpg" alt="pwl999">
            
              <p class="site-author-name" itemprop="name">pwl999</p>
              <p class="site-description motion-element" itemprop="description">RTFSC(Read The Fucking Source Code)</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">30</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0、perf-event的组织"><span class="nav-number">1.</span> <span class="nav-text">0、perf_event的组织</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1、perf-event初始化"><span class="nav-number">2.</span> <span class="nav-text">1、perf_event初始化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2、perf-event-open系统调用"><span class="nav-number">3.</span> <span class="nav-text">2、perf_event_open系统调用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1、inherit"><span class="nav-number">3.1.</span> <span class="nav-text">2.1、inherit</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2、perf-task-sched"><span class="nav-number">3.2.</span> <span class="nav-text">2.2、perf task sched</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3、cgroup"><span class="nav-number">3.3.</span> <span class="nav-text">2.3、cgroup</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3、perf-ioctl"><span class="nav-number">4.</span> <span class="nav-text">3、perf_ioctl</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1、-perf-event-enable"><span class="nav-number">4.1.</span> <span class="nav-text">3.1、_perf_event_enable</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4、perf-read"><span class="nav-number">5.</span> <span class="nav-text">4、perf_read</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5、perf-mmap"><span class="nav-number">6.</span> <span class="nav-text">5、perf_mmap</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考资料："><span class="nav-number">7.</span> <span class="nav-text">参考资料：</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">pwl999</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.6.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.6.0"></script>



  
  <script src="/js/src/scrollspy.js?v=6.6.0"></script>
<script src="/js/src/post-details.js?v=6.6.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  

  
    <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
  

  
    <script>
      var disqus_config = function () {
        this.page.url = "http://yoursite.com/2018/12/21/perf_event_architecture/";
        this.page.identifier = "2018/12/21/perf_event_architecture/";
        this.page.title = 'Linux Perf 1.1、perf_event内核框架';
        };
      function loadComments () {
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      }
      
        loadComments();
      
    </script>
  





  











  





  

  

  

  

  

  
  

  

  

  

  

  

  

</body>
</html>
